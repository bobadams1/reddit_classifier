{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0371cdb1-ed20-4d08-8745-e19493d44d7c",
   "metadata": {},
   "source": [
    "# Model Fitting and Evalutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975f39b-5b89-4986-98b9-c8ad52908caf",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "b25aff06-ced7-4d60-8e25-323c105b7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "from sklearn.base import TransformerMixin # for class-driven multi-vectorizer assessment \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, mean_absolute_error, mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "# from functions.stem_post import *\n",
    "# from functions.lemmatize_post import *\n",
    "# from functions.model_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "4055044c-3567-4d18-a584-f761ea52a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_extract = '2023-06-11 16:25'\n",
    "df = pd.read_csv(f'data/reddit_posts_raw_{most_recent_extract}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "0bb092a5-94f3-42c0-b8ad-7c84a81271b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1971, 6)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "83ebf688-8ea0-4043-88eb-90c52d8becb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>top_comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dating</td>\n",
       "      <td>1471ube</td>\n",
       "      <td>2023-06-11 18:49:33</td>\n",
       "      <td>Am I Clueless?</td>\n",
       "      <td>So there is this girl I’ve known my whole life...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit       id          created_utc           title  \\\n",
       "0    dating  1471ube  2023-06-11 18:49:33  Am I Clueless?   \n",
       "\n",
       "                                            selftext top_comment_text  \n",
       "0  So there is this girl I’ve known my whole life...              NaN  "
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53578f0-9e88-4023-92ad-e103fa24003a",
   "metadata": {},
   "source": [
    "### Data Leveraged\n",
    "For this project, reddit posts were pulled from two subreddits: r/dating, and r/datingoverthirty.  Due to limitations with community access (Summer 2023 Reddit Blackout) and APIs (the removal of some of Reddit's APIs), sourcing data was impeded.  Approximately 1000 posts were sourced the day before protests began, constituting the working dataset used in EDA and Modeling.  To augment the information available, the text of the top-voted comment was pulled for each post.  This enables the investigation to cover broader community interaction.\n",
    "\n",
    "Comment text was interesting in EDA to understand the post-community response in each subreddit.  **Title, Selftext and Comment Text are all leveraged** to maximize the use of available data and to attempt to differentiate the communities based on the conversation (the post, and community-supported response.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53021088-c511-400b-ae95-5ea30d513cb5",
   "metadata": {},
   "source": [
    "#### Self-text Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "52b87f74-a99a-4930-a060-41a47fe7e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.Series(df['selftext'])\n",
    "# y = df['subreddit'].map({'dating': 0,\n",
    "#                     'datingoverthirty':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792701d4-b20f-48ca-ace2-e34628960c6a",
   "metadata": {},
   "source": [
    "#### Self Text and Top Comment - Alternative Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "e81dca47-8a62-4dc1-835b-67b92a603b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['self_text_and_comment'] = df['title'].astype(str) +' '+ df['selftext'].astype(str) +' '+ df['top_comment_text'].astype(str)\n",
    "X = pd.Series(df['self_text_and_comment'])\n",
    "y = df['subreddit'].map({'dating': 0,\n",
    "                   'datingoverthirty':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c0234-f3f8-4a5b-b6e5-bd6245d5e1de",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "0cf8e268-e628-47f6-937f-8bde2e2ab325",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "X_train.to_pickle('./pickled_models/X_train.pkl')\n",
    "X_test.to_pickle('./pickled_models/X_test.pkl')\n",
    "y_train.to_pickle('./pickled_models/y_train.pkl')\n",
    "y_test.to_pickle('./pickled_models/y_test.pkl')\n",
    "\n",
    "# X_train = pd.read_pickle('./pickled_models/X_train.pkl')\n",
    "# X_test = pd.read_pickle('./pickled_models/X_test.pkl')\n",
    "# y_train = pd.read_pickle('./pickled_models/y_train.pkl')\n",
    "# y_test = pd.read_pickle('./pickled_models/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "23c5fac9-ef9d-43b7-9118-b5b1e83238e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1703    Dating Steps & Intimacy I (36m) met a great wo...\n",
       "175     Levels of Cleanliness As many of us have reali...\n",
       "744     Random Any girl how is single and can't have i...\n",
       "1945    How to prevent conversations getting sexual be...\n",
       "680     How to attract more guys I am attracted to? Hi...\n",
       "Name: self_text_and_comment, dtype: object"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674e456-0407-4f36-897a-52dfdde06822",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c35f5f-2dd3-4ad8-934e-ec3bb2783183",
   "metadata": {},
   "source": [
    "> The majority class holds 50.63% of responses.  This is the baseline score to beat.\n",
    "\n",
    "> Even class distribution makes a 75/25 train test split possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "a934cc43-a7d1-499a-89c2-751b8e072a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5091277890466531"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_preds = dummy.predict(y_test)\n",
    "dummy_accuracy = accuracy_score(y_test, dummy_preds)\n",
    "dummy_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439cc05-bbd5-459b-8b93-93766af8f2f0",
   "metadata": {},
   "source": [
    "## Baseline Investigation with Standard Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e359a09-fe26-4bac-8415-e06dbdd1cdb9",
   "metadata": {},
   "source": [
    "Vectorizers perform differently on varying corpora.  This simple look in Model Investigations helps shed the light on how these vectorizers perform out of the box with selftext from these subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c4714-6c21-4912-bf6d-c11448013d92",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "8937a30d-1edb-4714-9028-2699ef3ce2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvec0 = CountVectorizer() #standard CountVectorizer\n",
    "cvec0.fit(X_train)\n",
    "pickle.dump(cvec0, open('./pickled_models/cvec0_baseline', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4df9b-d837-493c-95bb-03c7de07a16c",
   "metadata": {
    "tags": []
   },
   "source": [
    "> See Model Investigaion for Investigations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fc85f-1d24-4fc9-a9a4-be2d0c2eea52",
   "metadata": {},
   "source": [
    "#### Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "baf17ad6-346c-4dca-88eb-079fc3281c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tvec0 = TfidfVectorizer()\n",
    "tvec0.fit(X_train)\n",
    "pickle.dump(tvec0, open('./pickled_models/tvec0_baseline', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc3109-57f4-461d-84df-9e014ced471b",
   "metadata": {},
   "source": [
    "> See Model Investigation for Investigations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f253c1-1a47-4c5b-817d-a78af324a13e",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93724164-f8db-4116-9831-cfb423a2bc18",
   "metadata": {},
   "source": [
    "#### Model Performance Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c596d17-2f13-486e-a0e7-64615712ed89",
   "metadata": {},
   "source": [
    "##### Model Performance Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "8c5f8db7-2fd4-42b1-a21e-503244720f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Data Frame to capture output from each model fit.\n",
    "model_performance_capture = pd.DataFrame(columns = ['model_name', 'model', 'best_score_CV', 'train_acuracy', 'test_accuracy', 'baseline_accuracy','model_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "524f8ac9-eb94-4262-9cde-40afb3db0bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>best_score_CV</th>\n",
       "      <th>train_acuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>model_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, model, best_score_CV, train_acuracy, test_accuracy, baseline_accuracy, model_params]\n",
       "Index: []"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each model fit is recorded, including train, test, cross-validated accuracy scores, best scores, \n",
    "model_performance_capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea6fa8-f6a7-4399-9347-7804c8430ebd",
   "metadata": {},
   "source": [
    "#### Stemming and Lematizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848c670-f0dc-40ab-b790-05baea0a1c08",
   "metadata": {},
   "source": [
    "> Functions for Stemming and Lemmatizing are stored in separate files: stem_post.py, lemmatize_post.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "66c12595-e429-4d6f-85ef-4bdb583b4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "def stem_post(post):\n",
    "    split_post = post.split(' ')\n",
    "    return ' '.join([p_stemmer.stem(word) for word in split_post])\n",
    "#cite 6/9 Breakfast Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "7b46e54f-84c4-4c2d-a709-7a2767ad4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(stem_post, open('./pickled_models/function_stem_post.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "57cac3e0-718b-46a7-af1f-4217a6013053",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# cite: Lesson 504 NLP 1 - Modified to handle complete words.\n",
    "def lemmatize_post(post):\n",
    "    mapper = { \n",
    "        'J': wordnet.ADJ,\n",
    "        'V': wordnet.VERB,\n",
    "        'N': wordnet.NOUN,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    post_split = post.split(' ')\n",
    "    post_tokens = [(token, tag) for token, tag in nltk.pos_tag(post_split)]\n",
    "    post_lem = []\n",
    "    for token in post_tokens:\n",
    "        pos = mapper.get(token[1][0])\n",
    "        # post_lem.append((token[0],pos) if pos != None else (token[0]))\n",
    "        post_lem.append(lemmatizer.lemmatize(token[0], pos) if pos != None else token[0])\n",
    "    return ' '.join(post_lem).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "f085bfe4-8bca-4ee6-b77a-d8650845ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(lemmatize_post, open('./pickled_models/function_lemmatize_post', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dffd3a-0416-479d-9e91-d7dbd139907e",
   "metadata": {},
   "source": [
    "#### Multiple Estimator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "05cd6f3a-0294-496e-931e-58c096f06156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating multiple classifiers in the same RandomSearchCV, trying different combinations of Tfidf / CountVectorizer and LogisticRegression() / MultinomialNB\n",
    "# Inspiration: Wrapper Class (https://stackoverflow.com/questions/50285973/pipeline-multiple-classifiers).  Content: DSI Lesson 507 on OOP (https://git.generalassemb.ly/bobadams1/507-lesson-object-oriented-programming)\n",
    "'''\n",
    "Notes from Inspiration above (no copy-paste):\n",
    "1. Need BaseEstimator() as the base class for all sklearn estimators - as a stand in for the estimator being selected\n",
    "2. The class only really needs to to have self and the estimator as objects in the class.\n",
    "3. The methods you would normally call for the estimator should be defined as functions within the model (don't forget to pass self every time!)\n",
    "'''\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Multi_Classifier(BaseEstimator):\n",
    "    def __init__(self, estimator = MultinomialNB()): #Multinomial NB as default\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def fit(self, X, y): # interested in LogisticRegression, NB... both take primarily X,y\n",
    "        return self.estimator.fit(X,y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "    \n",
    "    def score(self, X,y):\n",
    "        return self.estimator.score(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d9e3b-8203-4817-a9c6-5d09370523cf",
   "metadata": {},
   "source": [
    "#### Model Evaluation - Centralized Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "5c1a9df6-8671-43c9-a0f1-fa4cb7f8fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "def model_evaluation(model, model_name):\n",
    "    \n",
    "    # print(model_performance)\n",
    "    \n",
    "    #Print Model Evaluations to the screen\n",
    "    print(f\"Train-Test Accuracy Scores:\\n  Train: {round(model.score(X_train, y_train),5)} \\n  Test: {round(model.score(X_test, y_test),5)}\\n  Baseline: {round(dummy_accuracy,5)}\\n---\")\n",
    "    print(f\"\\n Classification Report:\\n{classification_report(y_test, model.predict(X_test), digits = 4)}\")\n",
    "    print(f\"\\n---\\nBest Parameters: \\n{model.best_params_}\")\n",
    "    \n",
    "    # Plot and Save the Confusion Matrix\n",
    "    preds = model.predict(X_test)\n",
    "    plt.figure(figsize = (8,5))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, preds, cmap = 'YlOrBr', display_labels=['r/dating','r/datingoverthirty'])\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    # plt.suptitle('Stop Words: English | Unigrams and Bigrams | Max Documents:90% | No Stem/Lem | LogisticRegression', y=0, fontsize = 9)\n",
    "    plt.savefig(fname= f'./images/{model_name}_Confusion Matrix.png', bbox_inches = 'tight', dpi = 200)\n",
    "    plt.show()\n",
    "    \n",
    "    #Append results of key metrics to \n",
    "    # pd.concat(model_performance_capture,\n",
    "    model_performance = pd.DataFrame({\n",
    "        'model_name' : model_name,\n",
    "        'model' : model,\n",
    "        'best_score_CV' : model.best_score_,\n",
    "        'train_acuracy' : model.score(X_train, y_train),\n",
    "        'test_accuracy' : model.score(X_test, y_test),\n",
    "        'baseline_accuracy' : dummy_accuracy,\n",
    "        'model_params' : [model.best_params_]\n",
    "        })\n",
    "\n",
    "    return model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdefba46-5a7f-4f3f-b223-8fb98e0f6ead",
   "metadata": {},
   "source": [
    "## Multiple-Evaluator Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9b446-9390-4b88-bb83-c473c9609104",
   "metadata": {},
   "source": [
    "### 01 - RandomSearch over Multiple Estimators with Tfidf Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ddd8c8-5ab3-4535-b072-dab124957860",
   "metadata": {},
   "source": [
    "#### Pipeline & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "8b41831c-f116-4628-b840-075752cf6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([\n",
    "    ('tvec' , TfidfVectorizer()),\n",
    "    # ('sc', StandardScaler()),\n",
    "    ('cls' , Multi_Classifier())\n",
    "])\n",
    "\n",
    "tvec_params1 = {'tvec__preprocessor': [lemmatize_post],     # Lemmatizing showed the best results in initial testing\n",
    "                'tvec__max_df': [1.0, 0.9],\n",
    "                'tvec__max_features': [None, 5000],\n",
    "                'tvec__min_df': [1],\n",
    "                'tvec__ngram_range': [(1,2)],               #words and bigrams showed best results early\n",
    "                'tvec__stop_words': ['english'] }\n",
    "\n",
    "logr_params1 = {'cls__estimator': [LogisticRegression()],\n",
    "                'cls__estimator__C': np.linspace(0.9, 2, 9)}\n",
    "\n",
    "mnb_params1 = {'cls__estimator': [MultinomialNB()]}\n",
    "\n",
    "ksvm_params1 = {'cls__estimator': [SVC()],\n",
    "                'cls__estimator__C': np.linspace(0.05, 2, 7),\n",
    "                'cls__estimator__degree': [2,3],\n",
    "                'cls__estimator__kernel': ['poly','rbf']}\n",
    "\n",
    "\n",
    "params1 = [# list of params... one for each estimator (order matters here). Cite: Tim Office Hours\n",
    "        # Logistic Regression\n",
    "        tvec_params1 | logr_params1\n",
    "        # Multinomial Naive Bayes\n",
    "        ,tvec_params1 | mnb_params1\n",
    "        #Kernelized SVM\n",
    "        ,tvec_params1 | ksvm_params1\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "3634f8bd-9429-481d-9f12-aad28a337c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs1 = RandomizedSearchCV(estimator=pipe0,\n",
    "                        param_distributions=params0,\n",
    "                        cv = 5,\n",
    "                        n_iter = 100\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795b264-fb94-45af-a4d3-17fddebf17ba",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "d9aff007-a2ae-4a50-8a6b-7bc71fffe696",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 51 is smaller than n_iter=100. Running 51 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function lemmatize_post at 0x7fbf48805510>: it's not the same object as __main__.lemmatize_post",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[515], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m rs1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./pickled_models/rs1_multi_tvec.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function lemmatize_post at 0x7fbf48805510>: it's not the same object as __main__.lemmatize_post"
     ]
    }
   ],
   "source": [
    "%time\n",
    "rs1.fit(X_train, y_train)\n",
    "# pickle.dump(rs1, open('./pickled_models/rs1_multi_tvec.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3fb95-12d5-4b3d-be2c-959df629c0e5",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "ff55cf62-d44e-41ab-b098-e4127cbe1f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Accuracy Scores:\n",
      "  Train: 1.0 \n",
      "  Test: 0.79919\n",
      "  Baseline: 0.50913\n",
      "---\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8743    0.6901    0.7714       242\n",
      "           1     0.7517    0.9044    0.8210       251\n",
      "\n",
      "    accuracy                         0.7992       493\n",
      "   macro avg     0.8130    0.7972    0.7962       493\n",
      "weighted avg     0.8119    0.7992    0.7966       493\n",
      "\n",
      "\n",
      "---\n",
      "Best Parameters: \n",
      "{'tvec__stop_words': 'english', 'tvec__preprocessor': <function lemmatize_post at 0x7fbf48805510>, 'tvec__ngram_range': (1, 2), 'cls__estimator__kernel': 'rbf', 'cls__estimator__degree': 2, 'cls__estimator__C': 1.5666666666666667, 'cls__estimator': SVC(C=1.5666666666666667, degree=2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/4sqt0lt90t72lgqr2zq3p6l80000gn/T/ipykernel_33031/1195430848.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_performance_capture = model_performance_capture.append(model_evaluation(rs1, 'Model_1_RSCV_Multi_Tfidf'))\n"
     ]
    }
   ],
   "source": [
    "model_performance_capture = model_performance_capture.append(model_evaluation(rs1, 'Model_1_RSCV_Multi_Tfidf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351f11b-115a-467c-a4c6-4d1c8f882ba5",
   "metadata": {},
   "source": [
    "### 02 - RandomSearchCV over Multiple Estimators with CountVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79c4d0-18c5-49fc-b11c-327a173c29bd",
   "metadata": {},
   "source": [
    "#### Pipeline and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "3eb4b70e-317c-4068-bea6-7b27cf3af673",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([\n",
    "    ('cvec' , CountVectorizer()),\n",
    "    ('cls' , Multi_Classifier())\n",
    "])\n",
    "\n",
    "cvec_params2 = {'cvec__max_df': [0.95, 0.9, 0.85],\n",
    "         'cvec__ngram_range': [(1, 1), (1,2)],\n",
    "         'cvec__preprocessor': [None, lemmatize_post],\n",
    "         'cvec__stop_words': [None, 'english']}\n",
    "\n",
    "logr_params2 = {'cls__estimator': [LogisticRegression()],\n",
    "                'cls__estimator__C': np.linspace(0.00001, 1, 9)}\n",
    "\n",
    "mnb_params2 = {'cls__estimator': [MultinomialNB()],}\n",
    "\n",
    "ksvm_params2 = {'cls__estimator': [SVC()],\n",
    "                 'cls__estimator__C': np.linspace(0.05, 2, 7),\n",
    "                 'cls__estimator__degree': [2,3],\n",
    "                 'cls__estimator__kernel': ['poly','rbf']}\n",
    "\n",
    "params2 = [ # list of params... one for each estimator (order matters here). Cite: Tim Office Hours\n",
    "            ## Logistic Regression\n",
    "            cvec_params2 | logr_params2      \n",
    "\n",
    "            ## Multinomial Naive Bayes\n",
    "             ,cvec_params2| mnb_params2\n",
    "    \n",
    "            #Kernelized SVM\n",
    "            ,cvec_params2 | ksvm_params2\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "2ab060a0-f6f2-4755-8ad3-ad3a7c63f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs2 = RandomizedSearchCV(estimator=pipe1,\n",
    "                        param_distributions=params1,\n",
    "                        cv = 5,\n",
    "                        n_iter = 100\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94bfb00-c0ac-41f4-af5b-43425ecb9c82",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "30c6a5b5-53ff-4568-acb4-a51680b81b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./pickled_models/rs2_multi_cvec.pkl', 'wb') as f:\n",
    "#     pickle.dump((rs2.best_estimator_, lemmatize_post), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "de81ba7a-e4cd-46ec-b735-e4811075153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(rs2.best_estimator_, open('./pickled_models/rs2_multi_cvec.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "4633b13e-6e5d-44d6-8164-d53ff90c3151",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;tvec&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;cls&#x27;, Multi_Classifier())]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions=[{&#x27;cls__estimator&#x27;: [LogisticRegression()],\n",
       "                                         &#x27;cls__estimator__C&#x27;: array([0.9   , 1.0375, 1.175 , 1.3125, 1.45  , 1.5875, 1.725 , 1.8625,\n",
       "       2.    ]),\n",
       "                                         &#x27;tvec__max_df&#x27;: [1.0, 0.9],\n",
       "                                         &#x27;tvec__max_features&#x27;: [None, 5000],\n",
       "                                         &#x27;tvec__min_df&#x27;: [1],\n",
       "                                         &#x27;tvec__ngram_...\n",
       "                                        {&#x27;cls__estimator&#x27;: [SVC(C=1.675,\n",
       "                                                                degree=2)],\n",
       "                                         &#x27;cls__estimator__C&#x27;: array([0.05 , 0.375, 0.7  , 1.025, 1.35 , 1.675, 2.   ]),\n",
       "                                         &#x27;cls__estimator__degree&#x27;: [2, 3],\n",
       "                                         &#x27;cls__estimator__kernel&#x27;: [&#x27;poly&#x27;,\n",
       "                                                                    &#x27;rbf&#x27;],\n",
       "                                         &#x27;tvec__max_df&#x27;: [1.0, 0.9],\n",
       "                                         &#x27;tvec__max_features&#x27;: [None, 5000],\n",
       "                                         &#x27;tvec__min_df&#x27;: [1],\n",
       "                                         &#x27;tvec__ngram_range&#x27;: [(1, 2)],\n",
       "                                         &#x27;tvec__preprocessor&#x27;: [&lt;function lemmatize_post at 0x7fbf28e22710&gt;],\n",
       "                                         &#x27;tvec__stop_words&#x27;: [&#x27;english&#x27;]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;tvec&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;cls&#x27;, Multi_Classifier())]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions=[{&#x27;cls__estimator&#x27;: [LogisticRegression()],\n",
       "                                         &#x27;cls__estimator__C&#x27;: array([0.9   , 1.0375, 1.175 , 1.3125, 1.45  , 1.5875, 1.725 , 1.8625,\n",
       "       2.    ]),\n",
       "                                         &#x27;tvec__max_df&#x27;: [1.0, 0.9],\n",
       "                                         &#x27;tvec__max_features&#x27;: [None, 5000],\n",
       "                                         &#x27;tvec__min_df&#x27;: [1],\n",
       "                                         &#x27;tvec__ngram_...\n",
       "                                        {&#x27;cls__estimator&#x27;: [SVC(C=1.675,\n",
       "                                                                degree=2)],\n",
       "                                         &#x27;cls__estimator__C&#x27;: array([0.05 , 0.375, 0.7  , 1.025, 1.35 , 1.675, 2.   ]),\n",
       "                                         &#x27;cls__estimator__degree&#x27;: [2, 3],\n",
       "                                         &#x27;cls__estimator__kernel&#x27;: [&#x27;poly&#x27;,\n",
       "                                                                    &#x27;rbf&#x27;],\n",
       "                                         &#x27;tvec__max_df&#x27;: [1.0, 0.9],\n",
       "                                         &#x27;tvec__max_features&#x27;: [None, 5000],\n",
       "                                         &#x27;tvec__min_df&#x27;: [1],\n",
       "                                         &#x27;tvec__ngram_range&#x27;: [(1, 2)],\n",
       "                                         &#x27;tvec__preprocessor&#x27;: [&lt;function lemmatize_post at 0x7fbf28e22710&gt;],\n",
       "                                         &#x27;tvec__stop_words&#x27;: [&#x27;english&#x27;]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tvec&#x27;, TfidfVectorizer()), (&#x27;cls&#x27;, Multi_Classifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cls: Multi_Classifier</label><div class=\"sk-toggleable__content\"><pre>Multi_Classifier()</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                             ('cls', Multi_Classifier())]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions=[{'cls__estimator': [LogisticRegression()],\n",
       "                                         'cls__estimator__C': array([0.9   , 1.0375, 1.175 , 1.3125, 1.45  , 1.5875, 1.725 , 1.8625,\n",
       "       2.    ]),\n",
       "                                         'tvec__max_df': [1.0, 0.9],\n",
       "                                         'tvec__max_features': [None, 5000],\n",
       "                                         'tvec__min_df': [1],\n",
       "                                         'tvec__ngram_...\n",
       "                                        {'cls__estimator': [SVC(C=1.675,\n",
       "                                                                degree=2)],\n",
       "                                         'cls__estimator__C': array([0.05 , 0.375, 0.7  , 1.025, 1.35 , 1.675, 2.   ]),\n",
       "                                         'cls__estimator__degree': [2, 3],\n",
       "                                         'cls__estimator__kernel': ['poly',\n",
       "                                                                    'rbf'],\n",
       "                                         'tvec__max_df': [1.0, 0.9],\n",
       "                                         'tvec__max_features': [None, 5000],\n",
       "                                         'tvec__min_df': [1],\n",
       "                                         'tvec__ngram_range': [(1, 2)],\n",
       "                                         'tvec__preprocessor': [<function lemmatize_post at 0x7fbf28e22710>],\n",
       "                                         'tvec__stop_words': ['english']}])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "rs2.fit(X_train, y_train)\n",
    "# pickle.dump(rs2, open('./pickled_models/rs2_multi_cvec.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0887909-7baa-450e-900a-36e76bae00fa",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "f8555740-ff8d-48a1-b823-27bde51202d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Accuracy Scores:\n",
      "  Train: 1.0 \n",
      "  Test: 0.80325\n",
      "  Baseline: 0.50913\n",
      "---\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8756    0.6983    0.7770       242\n",
      "           1     0.7567    0.9044    0.8240       251\n",
      "\n",
      "    accuracy                         0.8032       493\n",
      "   macro avg     0.8162    0.8014    0.8005       493\n",
      "weighted avg     0.8151    0.8032    0.8009       493\n",
      "\n",
      "\n",
      "---\n",
      "Best Parameters: \n",
      "{'tvec__stop_words': 'english', 'tvec__preprocessor': <function lemmatize_post at 0x7fbf28e22710>, 'tvec__ngram_range': (1, 2), 'tvec__min_df': 1, 'tvec__max_features': None, 'tvec__max_df': 1.0, 'cls__estimator__kernel': 'rbf', 'cls__estimator__degree': 2, 'cls__estimator__C': 1.675, 'cls__estimator': SVC(C=1.675, degree=2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAHFCAYAAABLm3WjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABl2ElEQVR4nO3deVgVZfsH8O9hO+wIIpsiIC65kCuuvYm5ohJqpigVCJplmuaamYKWa7llqZUKpJDWmwvuu7grqLjikqGiQhopm8r6/P7gx7weNs+BgzDy/VzXXHVmnnnmHs7Bc3M/z8wohBACRERERFTl6VR2AERERESkHiZuRERERDLBxI2IiIhIJpi4EREREckEEzciIiIimWDiRkRERCQTTNyIiIiIZIKJGxEREZFMMHEjIiIikgkmblRlXLhwAcOGDYOLiwsMDQ1hamqKVq1aYcGCBfj3338r9Njnzp1D586dYWFhAYVCgSVLlmj9GAqFAsHBwVrv90VCQ0OhUCigUChw6NChItuFEKhfvz4UCgU8PDzKdIzly5cjNDRUo30OHTpUYkza5O/vD4VCATMzM6SnpxfZfvv2bejo6Gj9/SnP+RW8Z7du3VJ7nzNnzuCTTz6Bm5sbzMzMYGtri27duuHAgQMaH78g9oJFV1cXtWrVgpeXF2JiYjTur0BmZia+//57vPHGG7C0tISBgQFq166NQYMGISoqCgDw2WefQaFQ4OrVqyX2M23aNCgUCpw9e1at4wYHB0OhUEBHRwd//fVXke0ZGRkwNzeHQqGAv79/mc7N398fzs7OKuvmzJmDzZs3F2lbns/G33//jc8//xxubm4wNTWFoaEhGjRogLFjx+LGjRsAgJYtW6J27drIzc0tsZ9OnTrB2toaWVlZuHXrlsr7XXgp7vdi69at8PLygq2tLQwMDGBlZYWuXbsiPDwc2dnZGp8XqY+JG1UJP//8M1q3bo3o6GhMmjQJu3btwqZNm/Duu+9i5cqVCAwMrNDjBwQEIDExEevXr8eJEyfg4+Oj9WOcOHECw4cP13q/6jIzM8Pq1auLrI+KisLNmzdhZmZW5r7Lkri1atUKJ06cQKtWrcp8XHXp6+sjJycHGzZsKLItJCSkXOdeVfz66684ffo0AgICsGXLFqxatQpKpRJdu3bFL7/8UqY+58yZgxMnTuDQoUOYPn06jh8/js6dO0sJgib++ecfdOrUCePHj0ezZs0QGhqK/fv3Y+HChdDV1UXXrl1x/vx56Xd9zZo1xfaTl5eHX375BS1atND4s2NqaoqQkJAi63///XdkZ2dDX19f4/MqTUmJW1k/+6dPn4abmxtWr16NgQMHYuPGjdi1axcmTpyIs2fPom3btgCAwMBA3L9/H7t37y62n+vXr+P48eN4//33YWBgIK0fM2YMTpw4UWR5/t8tIQSGDRuGt99+G3l5eVi0aBH27duHsLAwNG/eHKNGjcLy5cs1Oi/SkCCqZMePHxe6urqiV69e4tmzZ0W2Z2Zmii1btlRoDHp6euLjjz+u0GNUlpCQEAFADB8+XBgZGYmUlBSV7e+9957o0KGDaNq0qejcuXOZjqHJvllZWSI7O7tMxykLPz8/YWJiInx8fETHjh1VtuXl5QknJycxYsQIAUAEBQVp7bgHDx4UAMTBgwc13rfgPYuPj1d7n7///rvIupycHPH6668LV1dXjY5fEPvvv/+usj4sLEwAEDNmzNCoPyGE8PT0FHp6emL//v3Fbj99+rS4ffu2EEKItm3bCjs7u2I/Jzt37hQAxLJly9Q+dlBQkPQ74OjoKHJzc1W2v/HGG2LIkCHCxMRE+Pn5qX9Sz/Hz8xNOTk4q68rTX2EpKSnCzs5OODo6ioSEhGLbFLxf//77rzA0NBTvvPNOse2mTJkiAIgLFy4IIYSIj48XAMQ333zzwjjmz58vAIiZM2cWuz0xMVEcOXJEnVOiMmLFjSrdnDlzoFAo8NNPP0GpVBbZbmBggLffflt6nZeXhwULFuC1116DUqmEjY0NPvjgA9y9e1dlPw8PDzRr1gzR0dH4z3/+A2NjY9SrVw/z5s1DXl4egP8NSeXk5GDFihXS0ADwv+GVwoobxjpw4AA8PDxQs2ZNGBkZoW7dunjnnXfw5MkTqU1xQw6XLl2Ct7c3LC0tYWhoiBYtWiAsLEylTcGwyq+//opp06bBwcEB5ubm6NatG65du6beDxnAkCFDAORXZgqkpKTgjz/+QEBAQLH7zJw5E+3atYOVlRXMzc3RqlUrrF69GkIIqY2zszMuX76MqKgo6edXMGRUEPvatWsxYcIE1K5dG0qlEn/++WeR4aJ//vkHjo6O6Nixo8pQy5UrV2BiYoL3339f7XMtTkBAAI4fP67yM9u3bx9u376NYcOGFbuPOu8PAFy9ehW9evWCsbExrK2t8dFHHyEtLa3YPvft24euXbvC3NwcxsbG6NSpE/bv31+ucwMAGxubIut0dXXRunVrJCQklLt/AGjTpg2A/OG65507dw59+/aFjY0NlEolHBwc0KdPH+l38syZM9i5cycCAwPx1ltvFdu3u7s76tatCyC/YpSUlISdO3cWaRcSEgKlUglfX1+N4w8ICEBCQgL27t0rrbt+/TqOHj1a7O9ASUPW6gx1KhQKZGRkICwsTPq9KJiKUJah0p9//hlJSUlYsGAB6tSpU2ybgQMHAgAsLS3Rv39/bN26FcnJySptcnNzsXbtWri7u8PNzU3t4wNAdnY25s+fj9deew3Tp08vto2dnR3eeOMNjfolzTBxo0qVm5uLAwcOoHXr1nB0dFRrn48//hhTpkxB9+7dERkZia+++gq7du1Cx44d8c8//6i0TUpKgq+vL9577z1ERkbC09MTU6dOxbp16wAAffr0wYkTJwDk/6NXMDSgiVu3bqFPnz4wMDDAmjVrsGvXLsybNw8mJibIysoqcb9r166hY8eOuHz5Mr777jts3LgRTZo0gb+/PxYsWFCk/RdffIHbt29j1apV+Omnn3Djxg14eXmVOo/leebm5hg4cKDKENSvv/4KHR0dDB48uMRzGzlyJH777Tds3LgRAwYMwJgxY/DVV19JbTZt2oR69eqhZcuW0s9v06ZNKv1MnToVd+7cwcqVK7F169Zikwxra2usX78e0dHRmDJlCgDgyZMnePfdd1G3bl2sXLlSalvwxafJnLRu3brByclJ5fxXr16NN998Ew0aNCjSXt335++//0bnzp1x6dIlLF++HGvXrkV6ejpGjx5dpM9169ahR48eMDc3R1hYGH777TdYWVmhZ8+eWkneCsvJycGRI0fQtGlTrfQXHx8PAGjYsKG0LiMjA927d8fff/+NH374AXv37sWSJUtQt25dKXnds2cPAKBfv35qHWfIkCEwNjYuMlz66NEjbNmyBf3794elpaXG8Tdo0AD/+c9/VPpds2YNnJ2d0bVrV437K82JEydgZGSE3r17S78X5RlC3LNnD3R1deHl5aVW+8DAQGRlZUn/1hXYvXs37t+/X+z0k7y8POTk5BRZCsTExODff/+Ft7d3sX/U0ktS2SU/qt6SkpIEAOHj46NW+7i4OAFAjBo1SmX9qVOnBADxxRdfSOs6d+4sAIhTp06ptG3SpIno2bOnyjoA4pNPPlFZVzC8UljhYaz//ve/AoCIjY0tNXYUGorz8fERSqVS3LlzR6Wdp6enMDY2Fo8fPxZC/G/Yqnfv3irtfvvtNwFAnDhxotTjFsQbHR0t9XXp0iUhhBDu7u7C399fCPHi4c7c3FyRnZ0tZs2aJWrWrCny8vKkbSXtW3C8N998s8RthYcSC4ZiNm3aJPz8/ISRkZE0pFPg0KFDQldXt8ThmucVDJUKkf+eFgzBJScnC6VSKUJDQ8XDhw/L/P5MmTJFKBSKIu9/9+7dVc4vIyNDWFlZCS8vL5V2ubm5onnz5qJt27bSurIMlRZn2rRpAoDYvHmzRvsVvDcbNmwQ2dnZ4smTJ+LYsWOiUaNGokmTJuLRo0dS25iYmBce46OPPhIAxNWrV9WOwc/PT+jr66sMAS9btkwAEHv37tXofAp+lx8+fChCQkKEUqkUycnJIicnR9jb24vg4GAhRNGhzZLeh+I+u5oMlZZlGP21114TdnZ2arfPy8sTLi4u4vXXX1dZ/8477whjY2OVKRMFQ6UlLQVDn+vXrxcAxMqVK9WOg7SPFTeSlYMHDwJAkSu/2rZti8aNGxepWtjZ2UkTdgu8/vrruH37ttZiatGiBQwMDPDhhx8iLCys2KvWinPgwAF07dq1SKXR398fT548KVL5e364GMg/DwAanUvnzp3h6uqKNWvW4OLFi4iOji5xmLQgxm7dusHCwgK6urrQ19fHjBkzkJycjAcPHqh93HfeeUfttpMmTUKfPn0wZMgQhIWFYdmyZUWGdDp37oycnBzMmDFD7X4BYNiwYfj777+xc+dOhIeHw8DAAO+++26xbdV9fw4ePIimTZuiefPmKu2GDh2q8vr48eP4999/4efnp1LNyMvLQ69evRAdHY2MjAyNzqc0q1atwuzZszFhwgR4e3uXqY/BgwdDX19fGtJNTU3F9u3bUaNGDalN/fr1YWlpiSlTpmDlypW4cuWKVuIPDAxEdnY21q5dK60LCQmBk5NTuapj7777LgwMDBAeHo4dO3YgKSmpzFeSVmUKhQLDhg3DhQsXcObMGQBAcnIytm7dinfeeQfm5uZF9hk7diyio6OLLC1atHjJ0VNpmLhRpbK2toaxsbE0BPMiBfM17O3ti2xzcHAoMp+jZs2aRdoplUo8ffq0DNEWz9XVFfv27YONjQ0++eQTuLq6wtXVFUuXLi11v+Tk5BLPo2D78wqfS8F8QE3OpeAf83Xr1mHlypVo2LAh/vOf/xTb9vTp0+jRoweA/Pk1x44dQ3R0NKZNm6bxcYs7z9Ji9Pf3x7Nnz2BnZ1fuuW3PK/jSX7NmDdasWQMfHx8YGxsX21bd9yc5ORl2dnZF2hVeVzAvbODAgdDX11dZ5s+fDyGE1m57ExISgpEjR+LDDz/EN998U+Z+5s+fj+joaERFRWHatGn4+++/0a9fP2RmZkptLCwsEBUVhRYtWuCLL75A06ZN4eDggKCgIGmuYsHcNXV/zwHgP//5Dxo2bChdBXrhwgWcPXsWw4YNK9cwnYmJCQYPHow1a9Zg9erV0hB6VVe3bl08fPhQo+R+2LBh0NHRkX6G4eHhyMrKKvEq/Tp16qBNmzZFFlNTUykGQLP3kbSPiRtVqoLbAJw5c6bIxQXFKUheEhMTi2y7f/8+rK2ttRaboaEhAKh8SQEoMo8OyP+S2bp1K1JSUnDy5El06NAB48aNw/r160vsv2bNmiWeBwCtnsvz/P398c8//2DlypUlTsoHgPXr10NfXx/btm3DoEGD0LFjR2lyuqY0+aJNTEzEJ598ghYtWiA5ORkTJ04s0zFLEhAQgMjISMTGxpZabVT3/alZsyaSkpKKtCu8rqD9smXLiq1qREdHw9bWtsznVSAkJATDhw+Hn58fVq5cWa4kp169emjTpg3efPNNfP3115g1axbOnz+PZcuWqbRzc3PD+vXrkZycjNjYWAwePBizZs3CwoULAQA9e/YEgGJvjVGagIAAXL58GadPn8aaNWugo6OjlepYQEAAYmNjsXXr1lI/A5r8G1DRevbsidzcXGzdulXtferUqYMePXogIiICmZmZCAkJQf369fHmm2+WKYY2bdrAysoKW7ZsUblAiV4uJm5U6aZOnQohBEaMGFHsZP7s7GzpH6uCK9IKT7iNjo5GXFycVicYF1wZeeHCBZX1pf3Dqauri3bt2uGHH34AgFJvENq1a1ccOHBASgQK/PLLLzA2Nkb79u3LGHnpateujUmTJsHLywt+fn4ltlMoFNDT04Ourq607unTpypDVwW0VcXMzc3FkCFDoFAosHPnTsydOxfLli3Dxo0by913gf79+6N///4ICAgo9Wes7vvTpUsXXL58GefPn1dpFxERofK6U6dOqFGjBq5cuVJsVaNNmzYq99Qqi9DQUAwfPhzvvfceVq1apfUJ5JMnT0b9+vUxb968Yq+aVSgUaN68ORYvXowaNWpIn/9WrVrB09MTq1evLvGGwDExMbhz547KOj8/P+jp6eHHH39EeHg4unbtqpXqWIcOHRAQECB9FkpS0r8BkZGRah1Hm9X9wMBA2NnZYfLkybh3716xbYr7PQkMDMSjR48wY8YMxMbGlqtiqa+vjylTpuDq1asqFyg978GDBzh27FiZ+if16FV2AEQdOnTAihUrMGrUKLRu3Roff/wxmjZtiuzsbJw7dw4//fQTmjVrBi8vLzRq1Agffvghli1bBh0dHXh6euLWrVuYPn06HB0d8dlnn2ktrt69e8PKygqBgYGYNWsW9PT0EBoaWuTWCitXrsSBAwfQp08f1K1bF8+ePZOuWuvWrVuJ/QcFBWHbtm3o0qULZsyYASsrK4SHh2P79u1YsGABLCwstHYuhc2bN++Fbfr06YNFixZh6NCh+PDDD5GcnIxvv/222Fu2FFRcNmzYgHr16sHQ0FDjWw0A+T+TI0eOYM+ePbCzs8OECRMQFRWFwMBAtGzZEi4uLgDybxrctWtXzJgxQ+N5boaGhvjvf/+rVizqvD/jxo3DmjVr0KdPH3z99dewtbVFeHh4kTv/m5qaYtmyZfDz88O///6LgQMHwsbGBg8fPsT58+fx8OFDrFixQqNzed7vv/+OwMBAtGjRAiNHjsTp06dVtrds2bLY904T+vr6mDNnDgYNGoSlS5fiyy+/xLZt27B8+XL069cP9erVgxACGzduxOPHj9G9e3dp319++QW9evWCp6cnAgIC4OnpCUtLSyQmJmLr1q349ddfcebMGWk4Dsgfbu7duzdCQkIghNDqjbiLuxl1Ye7u7mjUqBEmTpyInJwcWFpaYtOmTTh69Khax3Bzc8OhQ4ewdetW2Nvbw8zMDI0aNSpTvBYWFtiyZQv69u2Lli1bYvTo0ejQoQMMDAxw48YNrFu3DufPn8eAAQNU9nv77bdhbW2Nb775Brq6uqX+sXbnzh2cPHmyyPpatWrB1dUVQP4c1Li4OAQFBeH06dMYOnQoHB0dkZKSgsOHD+Onn37CzJkz0alTpzKdJ6mhUi+NIHpObGys8PPzE3Xr1hUGBgbCxMREtGzZUsyYMUM8ePBAapebmyvmz58vGjZsKPT19YW1tbV47733ityUsnPnzqJp06ZFjlPc1V8o5qpSIfJvCtqxY0dhYmIiateuLYKCgsSqVatUrjQ7ceKE6N+/v3BychJKpVLUrFlTdO7cWURGRhY5RuEbvF68eFF4eXkJCwsLYWBgIJo3by5CQkJU2pR0M9SCK8EKty/s+atKS1PclaFr1qwRjRo1EkqlUtSrV0/MnTtXrF69usiVdrdu3RI9evQQZmZmAoD08y0p9ue3FVxZt2fPHqGjo1PkZ5ScnCzq1q0r3N3dRWZmpsq+6tww9/mrSktS3FWlQqj3/gghxJUrV0T37t2FoaGhsLKyEoGBgWLLli3FXjkYFRUl+vTpI6ysrIS+vr6oXbu26NOnj8rPqCxXlfr5+ZV6ZaAmfZX2vgkhRLt27YSlpaV4/PixuHr1qhgyZIhwdXUVRkZGwsLCQrRt21aEhoYW2e/p06fiu+++Ex06dBDm5uZCT09PODg4iAEDBojt27cXe6yCn6OVlVWxN+hWx/NXlZamuKtAr1+/Lnr06CHMzc1FrVq1xJgxY8T27dvVuqo0NjZWdOrUSRgbGwsA0u9XeW7OnJSUJKZMmSKaNm0qjI2NhVKpFPXr1xcjR44UFy9eLHafzz77rNgr0wu86KpSX1/fIvts2bJF9OnTR9SqVUvo6ekJS0tL0aVLF7Fy5Urp95QqhkIIDlQTERERyQHnuBERERHJBOe4ERFVYUKIFz4dQ1dXV60J59rsqyrIy8uTHl9XEj29qv0196q9J1TxWHEjIqrCwsLCitz3rfASFRX10vuqCgICAl54PlVdVFTUC8+huOfjUvXFOW5ERFVYcnLyC2942qhRI5iZmb3UvqqCW7duvfCeamW99+DLkpaWhmvXrpXaxsXFpdibiVP1xMSNiIiISCY4VEpEREQkE1V71iZVG3l5ebh//z7MzMw4CZeISGaEEEhLS4ODgwN0dCquJvTs2bNin7BTFgYGBtJjzUozd+5cbNy4EVevXoWRkRE6duyI+fPnSzdTzs7OxpdffokdO3bgr7/+goWFBbp164Z58+ZJzzYGAA8PjyJzSAcPHlzqoxGLw6FSqhLu3r0LR0fHyg6DiIjKISEhAXXq1KmQvp89ewYrUyM8Lf0iXLXZ2dkhPj7+hclbr1694OPjA3d3d+Tk5GDatGm4ePEirly5AhMTE6SkpGDgwIEYMWIEmjdvjkePHmHcuHHIyclBTEyM1I+HhwcaNmyIWbNmSeuMjIw0fkoOEzeqElJSUlCjRg3s76sPU31W3OjV1GjO7MoOgahCpKY/Q1336Xj8+HGFPa4vNTUVFhYWGOqsD4NyFvWy8oCIW9lISUmBubm5Rvs+fPgQNjY2iIqKwptvvllsm+joaLRt2xa3b9+WHuPm4eGBFi1aYMmSJeWKnUOlVCUUDI+a6iuYuNEry9zMqLJDIKpQL2Oqi6EOYKBbvuPooOw1q5SUFACAlZVVqW0UCgVq1Kihsj48PBzr1q2Dra0tPD09ERQUpPFV3EzciIiISDYUivylvH0A+VW85ymVSiiVyhL3E0Jg/PjxeOONN9CsWbNi2zx79gyff/45hg4dqlLN8/X1hYuLC+zs7HDp0iVMnToV58+fx969ezWKnYkbERERyYYOyn9LjIL9C8+tDgoKQnBwcIn7jR49GhcuXMDRo0eL3Z6dnQ0fHx/k5eVh+fLlKttGjBgh/X+zZs3QoEEDtGnTBmfPnkWrVq3Ujp2JGxEREVVLCQkJKlWx0qptY8aMQWRkJA4fPlzsBRjZ2dkYNGgQ4uPjceDAgRfOnWvVqhX09fVx48YNJm5ERET0atLmUKm5ufkLEywhBMaMGYNNmzbh0KFDcHFxKdKmIGm7ceMGDh48qNaTLi5fvozs7GzY29trFDsTNyIiIpINBco/VKpJ3vfJJ58gIiICW7ZsgZmZGZKSkgAAFhYWMDIyQk5ODgYOHIizZ89i27ZtyM3NldpYWVnBwMAAN2/eRHh4OHr37g1ra2tcuXIFEyZMQMuWLdGpUyeNYmfiRkRERFSCFStWAMi/ncfzQkJC4O/vj7t37yIyMhIA0KJFC5U2Bw8ehIeHBwwMDLB//34sXboU6enpcHR0RJ8+fRAUFARdXV2N4mHiRkRERLKho8hfytuHul50u1tnZ+cXtnF0dCzy1ISyYuJGREREsqGAZkOdJfUhV3zIPBEREZFMsOJGREREsqGjEFoYKpXv0z6ZuBEREZFscKiUiIiIiGSBFTciIiKSjZd9VWlVw8SNiIiIZEObzyqVIyZuREREJBvafOSVHMk56SQiIiKqVlhxIyIiItngUCkRERGRTHColIiIiIhkgRU3IiIikg0OlRIRERHJhEIL93HjUCkRERERVThW3IiIiEg2qvuzSpm4ERERkWxU9zluco6diIiIqFphxY2IiIhko7rfx42JGxEREclGdR8qZeJGREREsqGjhduBlHf/yiTnpJOIiIioWmHFjYiIiGSDtwMhIiIikgkOlRIRERGRLLDiRkRERLKhgNDCUKnQSiyVgYkbERERyQaHSomIiIhIFlhxIyIiItngDXiJiIiIZKK6P/JKzkknERERUbXCihsRERHJhgLlrzrJuODGxI2IiIjko7oPlTJxIyIiItmo7hcnyDl2IiIiomqFiRsRERHJRsENeMu7qGvu3Llwd3eHmZkZbGxs0K9fP1y7dk2ljRACwcHBcHBwgJGRETw8PHD58mWVNpmZmRgzZgysra1hYmKCt99+G3fv3tX8/DXeg4iIiKiSKLS0qCsqKgqffPIJTp48ib179yInJwc9evRARkaG1GbBggVYtGgRvv/+e0RHR8POzg7du3dHWlqa1GbcuHHYtGkT1q9fj6NHjyI9PR19+/ZFbm6uRufPOW5EREREJdi1a5fK65CQENjY2ODMmTN48803IYTAkiVLMG3aNAwYMAAAEBYWBltbW0RERGDkyJFISUnB6tWrsXbtWnTr1g0AsG7dOjg6OmLfvn3o2bOn2vGw4kZERESyoc2h0tTUVJUlMzPzhcdPSUkBAFhZWQEA4uPjkZSUhB49ekhtlEolOnfujOPHjwMAzpw5g+zsbJU2Dg4OaNasmdRG7fPXqDURERFRJSq4HUh5FwBwdHSEhYWFtMydO7fUYwshMH78eLzxxhto1qwZACApKQkAYGtrq9LW1tZW2paUlAQDAwNYWlqW2EZdHColIiKiaikhIQHm5ubSa6VSWWr70aNH48KFCzh69GiRbYpCN4cTQhRZV5g6bQpjxY2IiIhkQ0dLCwCYm5urLKUlbmPGjEFkZCQOHjyIOnXqSOvt7OwAoEjl7MGDB1IVzs7ODllZWXj06FGJbTQ5fyIiIiJZ0IEW5rhpcDwhBEaPHo2NGzfiwIEDcHFxUdnu4uICOzs77N27V1qXlZWFqKgodOzYEQDQunVr6Ovrq7RJTEzEpUuXpDbq4lApERERUQk++eQTREREYMuWLTAzM5MqaxYWFjAyMoJCocC4ceMwZ84cNGjQAA0aNMCcOXNgbGyMoUOHSm0DAwMxYcIE1KxZE1ZWVpg4cSLc3Nykq0zVxcSNiIiIZONlP6t0xYoVAAAPDw+V9SEhIfD39wcATJ48GU+fPsWoUaPw6NEjtGvXDnv27IGZmZnUfvHixdDT08OgQYPw9OlTdO3aFaGhodDV1dUsdiGE0GgPogqQmpoKCwsLnOpvAFN9GT/9l6gUjRctrOwQiCpEatpT1Gg8CSkpKSqT/bV6jP//nvjJXRdGeuX7nniaI/BhdG6FxltRWHEjIiIiWanOf97z4gQiIiIimWDFjYiIiGRDRyE0ekh8SX3IFRM3IiIiko3nH1lVnj7kikOlRERERDLBihsRERHJxsu+HUhVw8SNiIiIZOP5R1aVpw+5knPsRERERNUKK25EREQkGxwqJSIiIpIJXlVKRERERLLAihsRERHJRnWvuDFxIyIiItlQoPzPKpVx3sbEjYiIiOSjulfcOMeNiIiISCZYcSMiIiLZ4O1AiIiIiGSCQ6VEREREJAusuBEREZFsKFD+qpOMC25M3IiIiEg+qvscNw6VEhEREckEK25EREQkG9X94gQmbkRERCQbHColIiIiIllgxY2IiIhkQwflrzrJuWrFxI2IiIhkQ0chtDDHTWgnmErAxI2IiIhkg3PciIiIiEgWWHEjIiIi2eDtQIiIiIhkQoHyP7JKxnkbh0qJiIiI5IIVt1dAaGgoxo0bh8ePH1eJfqhyGDd2R02vD2Ho0gz6VrZI+GYk0mL2qrQxqO0K26FTYNykHaBQIPPuDdxdPAY5yfcBAPq2dWH73lQYv9YGCj0DpJ8/jKSQmchN+acyTomoVF/4fIV//35UZH1n704YMu4dbA3dhZgDsXj08DH09HRRt2EdeAf2hksTp0qIlrRFB1oYKtVKJJWDiZtMuLi4YMWKFejVq5dW+nN2dsa4ceMwbtw4ad3gwYPRu3dvrfRPL5+O0hjPbsfh8aH/wnHCiiLb9W3rwnnmb3h88Dc8/H0Jcp+kQVm7PkR2JgBAoTSC0xdheHbnKm7Peg8AUGvwZ6g7+WfEfzkAEPK9fJ5eTVNXfoa8vDzp9f34JCyduBKtPJoDAGzr1ILP2AGwtq+J7Mxs7P9vFJZO/hFfrfsCZjVMKytsKifOcaMqKysrCwYGBrhw4QKSk5PRpUuXCj2ekZERjIyMKvQYVHHSY6OQHhtV4nYbnwlIP3cID8LnS+uyHyRI/2/cqDX0bergr8+9kPc0HQBwf8VkvLYmFibNOiLj4rGKC56oDAonX7sj9qOWQ000bO4KAGjbrbXK9oGjvHFsxyncu3kfr7Vu+NLiJNImOVcLXzkeHh4YPXo0xo8fD2tra3Tv3h0AsGXLFvTs2RNKpRJA/pBm3bp1YWxsjP79+yM5OVmln5s3b8Lb2xu2trYwNTWFu7s79u3bp3Kc27dv47PPPoNCoYDi/29oExoaiho1akjtgoOD0aJFC6xduxbOzs6wsLCAj48P0tLSpDZpaWnw9fWFiYkJ7O3tsXjxYnh4eKhU8qgKUChg2rILshLjUfeLUDT86TRcvt4Iszbd/9dEzwAQAiI7S1onsjIh8nJh3KhNZURNpLac7Byc2nsWHT3bSf+mFd5+ZNsJGJkYok59h0qIkLRG8b97uZV1kfPVCUzcqpiwsDDo6enh2LFj+PHHHwEAkZGR8Pb2BgCcOnUKAQEBGDVqFGJjY9GlSxd8/fXXKn2kp6ejd+/e2LdvH86dO4eePXvCy8sLd+7cAQBs3LgRderUwaxZs5CYmIjExMQS47l58yY2b96Mbdu2Ydu2bYiKisK8efOk7ePHj8exY8cQGRmJvXv34siRIzh79qy2fyxUTrrmNaFrZApr74+QHnsYt2f7ITV6D+pMWAHjxm0BAE9vxCIv8ylsfKdAYWAIhdIItu9NhUJHF3qWtSr5DIhKF3v0Ep6mP0WHXu4q6y+cuIyxnp9jTM8p2P/fKIz99iOYWnCYVM50tLRo4vDhw/Dy8oKDgwMUCgU2b96ssr2gCFJ4+eabb6Q2Hh4eRbb7+PhofP4cKq1i6tevjwULFkiv7927h/Pnz0tzz5YuXYqePXvi888/BwA0bNgQx48fx65du6R9mjdvjubNm0uvv/76a2zatAmRkZEYPXo0rKysoKurCzMzM9jZ2ZUaT15eHkJDQ2FmZgYAeP/997F//37Mnj0baWlpCAsLQ0REBLp27QoACAkJgYPDi/+azczMRGZmpvQ6NTX1hftQ2Sl08v+ZSovZh393rAEAZN6Og3HDVrDs7osncaeRm/Yv7i7+BPaBX8Gqlx8g8pBybCue/nUR4rl5RERV0fEdp9C03WuoYW2hsr5Ri/qYtmoC0lMycHTbSfw88xdMWT4W5pZmlRQpyVFGRgaaN2+OYcOG4Z133imyvXABZOfOnQgMDCzSdsSIEZg1a5b0uizTk5i4VTFt2qgOSUVGRqJTp06wsrICAMTFxaF///4qbTp06KCSuGVkZGDmzJnYtm0b7t+/j5ycHDx9+lSquGnC2dlZStoAwN7eHg8ePAAA/PXXX8jOzkbbtm2l7RYWFmjUqNEL+507dy5mzpypcTxUNjmpjyByspF574bK+sx7N2H82v/mAWVcOIo/x3aBrpklRG4O8p6koeGPp5D6YNvLDplIbclJ/yLu7HWMnDmsyDalkRI2tWvBpnYt1GvijOnvzcHxHafQy7dbJURK2lAZj7zy9PSEp6dnidsLF0G2bNmCLl26oF69eirrjY2NX1gweREOlVYxJiYmKq+fHyYFAKHGlX2TJk3CH3/8gdmzZ+PIkSOIjY2Fm5sbsrKyXrhvYfr6+iqvFQqFdBVXQSyF55OoE+PUqVORkpIiLQkJCS/ch8ohNxtPb16Agb3qPyIG9s7Ifni/aPO0R8h7kgbjph2ga14TaTH7irQhqiqO7zoNsxqmcOvQ+MWNhUB2dk7FB0UVpqRhSU0XIH+05/nl+ZGgsvr777+xfft2BAYGFtkWHh4Oa2trNG3aFBMnTlSZM64uVtyqsPT0dBw8eBA//PCDtK5JkyY4efKkSrvCr48cOQJ/f3+pMpeeno5bt26ptDEwMEBubm654nN1dYW+vj5Onz4NR0dHAPm/BDdu3EDnzp1L3VepVEoXW5B2KJTGMLD73/2p9G0coXRqjNz0FOQk30fy1p9RZ9x3eBJ3GhmXT8K0xZswa90Vt2YOlfax8BiIrHt/Iif1Xxg3aAlb/xn4d8caZCXGV8YpEb1QXl4eTuyKRoee7tDV1ZXWZz7NxM51+/B6p6awsDJHRuoTRG05hkcPU9C6c4vKC5jKTaGTv5S3DwDSd1eBoKAgBAcHl6vvsLAwmJmZYcCAASrrfX194eLiAjs7O1y6dAlTp07F+fPnsXfv3hJ6Kh4Ttyps165daNCggUqp9dNPP0XHjh2xYMEC9OvXD3v27FEZJgXy58lt3LgRXl5eUCgUmD59usq9joD8IdDDhw/Dx8cHSqUS1tbWGsdnZmYGPz8/TJo0CVZWVrCxsUFQUBB0dHSKvaqLKpaRqxucg36VXtv5fQkAeHzov7i/YjLSovcg8efpqNnvY9gNC0LW/b+QsGgUnl6LkfZR2teD7ZBJ0DW1QNaDe/hn03L8u331Sz8XInVdPXMD//79CB0926qs19HVQVLCA5wIikZGSgZMzE3g1MgRE78bDQeX8g1V0asjISEB5ubm0mttFBTWrFkDX19fGBoaqqwfMWKE9P/NmjVDgwYN0KZNG5w9exatWrVSu38mblXYli1bVIZJAaB9+/ZYtWqV9FdBt27d8OWXX+Krr76S2ixevBgBAQHo2LEjrK2tMWXKlCKT/2fNmoWRI0fC1dUVmZmZag1vFmfRokX46KOP0LdvX5ibm2Py5MlISEgo8oGlivfkyilcGVyv1DaPD/2Ox4d+L3H7g18X4MGvC0rcTlTVNHFvhJUHFxVZr2+gj49mFZ3zRvL3/FBn2fvI/6+5ublK4lZeR44cwbVr17Bhw4YXtm3VqhX09fVx48YNjRI3hSjrNzZVqNzcXNjY2GDnzp0qk/+ruoyMDNSuXRsLFy4sdny/JKmpqbCwsMCp/gYw1We1jl5NjRctrOwQiCpEatpT1Gg8CSkpKVpNhFSO8f/fE0f76pb7eyI9W+CNbbllilehUGDTpk3o169fkW3+/v64dOkSYmJiiu5YyKVLl+Dm5oaoqCi8+eabah+fFbcqKjk5GZ999hnc3d1f3LgSnTt3DlevXkXbtm2RkpIiXeZcuFJIREQkV+np6fjzzz+l1/Hx8YiNjYWVlRXq1q0LID+x/P3337FwYdE/0G7evInw8HD07t0b1tbWuHLlCiZMmICWLVuiU6dOGsXCxK2KsrGxwZdfflnZYajl22+/xbVr12BgYIDWrVvjyJEjZZozR0RE9CLaHCpVV0xMjMpjJ8ePHw8A8PPzQ2hoKABg/fr1EEJgyJAhRfY3MDDA/v37sXTpUqSnp8PR0RF9+vRBUFCQykU1asXOoVKqCjhUStUBh0rpVfUyh0qPv62vlaHSjpHZFRpvReF93IiIiIhkgkOlREREJBuV8eSEqoSJGxEREclGZcxxq0o4VEpEREQkE6y4ERERkWxwqJSIiIhIJhQ6Cih0yjlUKuPxRiZuREREJBvVveIm45yTiIiIqHphxY2IiIhko7pfVcrEjYiIiGSDQ6VEREREJAusuBEREZFsKKCFoVItxVIZmLgRERGRfGhhjpucMzcOlRIRERHJBCtuREREJBvV/eIEJm5EREQkG9X9diAcKiUiIiKSCVbciIiISDYUOuV/1iifVUpERET0ElT3oVImbkRERCQb1f3iBBkXC4mIiIiqF1bciIiISDY4VEpEREQkE9U9ceNQKREREZFMsOJGREREslHdL05g4kZERESywaFSIiIiIpIFVtyIiIhINvjkBCIiIiKZ4FApEREREckCK25EREQkG7yqlIiIiEgmqvtQKRM3IiIiko38ilt5EzehpWhePs5xIyIiIpIJJm5EREQkGwr8b55bmRcNj3n48GF4eXnBwcEBCoUCmzdvVtnu7+8vDeEWLO3bt1dpk5mZiTFjxsDa2homJiZ4++23cffuXY3Pn4kbERERyUbhBKmsiyYyMjLQvHlzfP/99yW26dWrFxITE6Vlx44dKtvHjRuHTZs2Yf369Th69CjS09PRt29f5ObmahQL57gRERERlcLT0xOenp6ltlEqlbCzsyt2W0pKClavXo21a9eiW7duAIB169bB0dER+/btQ8+ePdWOhRU3IiIiko1yD5M+dzuR1NRUlSUzM7PMcR06dAg2NjZo2LAhRowYgQcPHkjbzpw5g+zsbPTo0UNa5+DggGbNmuH48eMaHYeJGxEREcmHjgKKci7Qyc/cHB0dYWFhIS1z584tU0ienp4IDw/HgQMHsHDhQkRHR+Ott96SEsGkpCQYGBjA0tJSZT9bW1skJSVpdCwOlRIREVG1lJCQAHNzc+m1UqksUz+DBw+W/r9Zs2Zo06YNnJycsH37dgwYMKDE/YQQGs+3Y8WNiIiI5EOLY6Xm5uYqS1kTt8Ls7e3h5OSEGzduAADs7OyQlZWFR48eqbR78OABbG1tNeqbiRsRERHJhjbnuFWU5ORkJCQkwN7eHgDQunVr6OvrY+/evVKbxMREXLp0CR07dtSobw6VEhERkXw8N0etXH1oID09HX/++af0Oj4+HrGxsbCysoKVlRWCg4PxzjvvwN7eHrdu3cIXX3wBa2tr9O/fHwBgYWGBwMBATJgwATVr1oSVlRUmTpwINzc36SpTdTFxIyIiIipFTEwMunTpIr0eP348AMDPzw8rVqzAxYsX8csvv+Dx48ewt7dHly5dsGHDBpiZmUn7LF68GHp6ehg0aBCePn2Krl27IjQ0FLq6uhrFwsSNiIiIZEM7D5nXbH8PDw8IUfLzTXfv3v3CPgwNDbFs2TIsW7ZMo2MXxsSNiIiIZEMbc9Qqeo5bReLFCUREREQywYobERERyUc1L7kxcSMiIiLZkJ5+UM4+5IpDpUREREQywYobERERyYfi/5fy9iFTaiVu3333ndodfvrpp2UOhoiIiKg0lXE7kKpErcRt8eLFanWmUCiYuBERERFVELUSt/j4+IqOg4iIiOjFdFD+GfoynuFf5tCzsrJw7do15OTkaDMeIiIiohIpoJCGS8u8yHiSm8aJ25MnTxAYGAhjY2M0bdoUd+7cAZA/t23evHlaD5CIiIioQLmTNi3MkatMGiduU6dOxfnz53Ho0CEYGhpK67t164YNGzZoNTgiIiIi+h+NbweyefNmbNiwAe3bt1fJWJs0aYKbN29qNTgiIiIiFbwdiGYePnwIGxubIuszMjJkXXokIiKiqo9PTtCQu7s7tm/fLr0uSNZ+/vlndOjQQXuREREREZEKjStuc+fORa9evXDlyhXk5ORg6dKluHz5Mk6cOIGoqKiKiJGIiIgoXzV/yLzGFbeOHTvi2LFjePLkCVxdXbFnzx7Y2trixIkTaN26dUXESERERATgf3lbeRe5KtOzSt3c3BAWFqbtWIiIiIioFGVK3HJzc7Fp0ybExcVBoVCgcePG8Pb2hp4en1lPREREFUhHkb+Utw+Z0jjTunTpEry9vZGUlIRGjRoBAK5fv45atWohMjISbm5uWg+SiIiICOBD5jWe4zZ8+HA0bdoUd+/exdmzZ3H27FkkJCTg9ddfx4cfflgRMRIRERERylBxO3/+PGJiYmBpaSmts7S0xOzZs+Hu7q7V4IiIiIieV80vKtW84taoUSP8/fffRdY/ePAA9evX10pQRERERMWq5peVqlVxS01Nlf5/zpw5+PTTTxEcHIz27dsDAE6ePIlZs2Zh/vz5FRMlEREREfjkBLUStxo1aqhM5BNCYNCgQdI6IQQAwMvLC7m5uRUQJhERERGplbgdPHiwouMgIiIiejE+ZP7FOnfuXNFxEBEREb1Qdb8dSJnvmPvkyRPcuXMHWVlZKutff/31cgdFREREREVpnLg9fPgQw4YNw86dO4vdzjluREREVGF0oIUnJ2glkkqhcejjxo3Do0ePcPLkSRgZGWHXrl0ICwtDgwYNEBkZWRExEhEREQH4/ylu5b0bSGWfRDloXHE7cOAAtmzZAnd3d+jo6MDJyQndu3eHubk55s6diz59+lREnERERETVnsYVt4yMDNjY2AAArKys8PDhQwCAm5sbzp49q93oiIiIiJ5XzW/AW6YnJ1y7dg0A0KJFC/z444+4d+8eVq5cCXt7e60HSERERFSg4KrS8i5ypfFQ6bhx45CYmAgACAoKQs+ePREeHg4DAwOEhoZqOz4iIiIi+n8aJ26+vr7S/7ds2RK3bt3C1atXUbduXVhbW2s1OCIiIqLnKXTyl/L2IVflDt3Y2BitWrVi0kZEREQVrxLmuB0+fBheXl5wcHCAQqHA5s2bpW3Z2dmYMmUK3NzcYGJiAgcHB3zwwQe4f/++Sh8eHh5Fhmt9fHw0Pn21Km7jx49Xu8NFixZpHAQRERGROirjyQkZGRlo3rw5hg0bhnfeeUdl25MnT3D27FlMnz4dzZs3x6NHjzBu3Di8/fbbiImJUWk7YsQIzJo1S3ptZGSkcexqJW7nzp1TqzM5T/YjIiIiKo6npyc8PT2L3WZhYYG9e/eqrFu2bBnatm2LO3fuoG7dutJ6Y2Nj2NnZlSsWPmSeqpTXQi/A3NysssMgqhAjGzpXdghEFSIrV7y8g+kotPDkhPz9U1NTVVYrlUoolcry9Q0gJSUFCoUCNWrUUFkfHh6OdevWwdbWFp6enggKCoKZmWbfeWV+VikRERHRS6eN+7D9//6Ojo4qq4OCghAcHFyurp89e4bPP/8cQ4cOhbm5ubTe19cXLi4usLOzw6VLlzB16lScP3++SLXuRZi4ERERUbWUkJCgklyVt9qWnZ0NHx8f5OXlYfny5SrbRowYIf1/s2bN0KBBA7Rp0wZnz55Fq1at1D6GjC+IJSIiompHi1eVmpubqyzlSdyys7MxaNAgxMfHY+/evSoJYXFatWoFfX193LhxQ6PjsOJGRERE8qHFOW7aUpC03bhxAwcPHkTNmjVfuM/ly5eRnZ2t8VOnmLgRERERlSI9PR1//vmn9Do+Ph6xsbGwsrKCg4MDBg4ciLNnz2Lbtm3Izc1FUlISgPxnuhsYGODmzZsIDw9H7969YW1tjStXrmDChAlo2bIlOnXqpFEsZRoqXbt2LTp16gQHBwfcvn0bALBkyRJs2bKlLN0RERERqacSbsAbExODli1bomXLlgDy72/bsmVLzJgxA3fv3kVkZCTu3r2LFi1awN7eXlqOHz8OADAwMMD+/fvRs2dPNGrUCJ9++il69OiBffv2QVdXV6NYNK64rVixAjNmzMC4ceMwe/Zs5ObmAgBq1KiBJUuWwNvbW9MuiYiIiNSjlWdeaXb7Eg8PDwhR8j6lbQPyr16NiorS6Jgl0fjMly1bhp9//hnTpk1TyRLbtGmDixcvaiUoIiIiIipK44pbfHy8VCp8nlKpREZGhlaCIiIiIipWFbw44WXSuOLm4uKC2NjYIut37tyJJk2aaCMmIiIiouJVwhy3qkTjitukSZPwySef4NmzZxBC4PTp0/j1118xd+5crFq1qiJiJCIiIvp/2ki8qlHiNmzYMOTk5GDy5Ml48uQJhg4ditq1a2Pp0qXw8fGpiBiJiIiICGW8j9uIESMwYsQI/PPPP8jLy4ONjY224yIiIiIqqprPcSvXDXitra21FQcRERHRi1XC7UCqEo0TNxcXFyhKGVv+66+/yhUQERERERVP48Rt3LhxKq+zs7Nx7tw57Nq1C5MmTdJWXERERERF6UALQ6VaiaRSaJy4jR07ttj1P/zwA2JiYsodEBEREVGJtHE7DxnfDkRrOaenpyf++OMPbXVHRERERIWU6+KE5/33v/+FlZWVtrojIiIiKqqaV9w0TtxatmypcnGCEAJJSUl4+PAhli9frtXgiIiIiFTwdiCa6devn8prHR0d1KpVCx4eHnjttde0FRcRERERFaJR4paTkwNnZ2f07NkTdnZ2FRUTERERUfGq+VCpRhcn6Onp4eOPP0ZmZmZFxUNERERUsoIb8JZ3kSmNI2/Xrh3OnTtXEbEQERERla5gjlt5F5nSeI7bqFGjMGHCBNy9exetW7eGiYmJyvbXX39da8ERERER0f+onbgFBARgyZIlGDx4MADg008/lbYpFAoIIaBQKJCbm6v9KImIiIiAaj/HTe3ELSwsDPPmzUN8fHxFxkNERERUMiZu6hFCAACcnJwqLBgiIiIiKplGc9wUMs5QiYiI6BXAG/Cqr2HDhi9M3v79999yBURERERUIm3czkPGtwPRKHGbOXMmLCwsKioWIiIiIiqFRombj48PbGxsKioWIiIiohfQwsUJqAZDpZzfRkRERJWums9xU3uQt+CqUiIiIiKqHGpX3PLy8ioyDiIiIqIX433ciIiIiGSCiRsRERGRTOgoAJ1y3s6jOsxxIyIiIqLKxYobERERyQeHSomIiIhkoponbhwqJSIiIpIJJm5EREQkHwU34C3vooHDhw/Dy8sLDg4OUCgU2Lx5s8p2IQSCg4Ph4OAAIyMjeHh44PLlyyptMjMzMWbMGFhbW8PExARvv/027t69q/npa7wHERERUWUpGCot76KBjIwMNG/eHN9//32x2xcsWIBFixbh+++/R3R0NOzs7NC9e3ekpaVJbcaNG4dNmzZh/fr1OHr0KNLT09G3b1/k5uZqFAvnuBERERGVwtPTE56ensVuE0JgyZIlmDZtGgYMGAAACAsLg62tLSIiIjBy5EikpKRg9erVWLt2Lbp16wYAWLduHRwdHbFv3z707NlT7VhYcSMiIiL5UOhoZwGQmpqqsmRmZmocTnx8PJKSktCjRw9pnVKpROfOnXH8+HEAwJkzZ5Cdna3SxsHBAc2aNZPaqIuJGxEREcmHFue4OTo6wsLCQlrmzp2rcThJSUkAAFtbW5X1tra20rakpCQYGBjA0tKyxDbq4lApERERVUsJCQkwNzeXXiuVyjL3pSg0b04IUWRdYeq0KYwVNyIiIpIPLQ6VmpubqyxlSdzs7OwAoEjl7MGDB1IVzs7ODllZWXj06FGJbdTFxI2IiIjkQ4uJmza4uLjAzs4Oe/fuldZlZWUhKioKHTt2BAC0bt0a+vr6Km0SExNx6dIlqY26OFRKRERE8qHQzV/K1UeeRs3T09Px559/Sq/j4+MRGxsLKysr1K1bF+PGjcOcOXPQoEEDNGjQAHPmzIGxsTGGDh0KALCwsEBgYCAmTJiAmjVrwsrKChMnToSbm5t0lam6mLgRERERlSImJgZdunSRXo8fPx4A4Ofnh9DQUEyePBlPnz7FqFGj8OjRI7Rr1w579uyBmZmZtM/ixYuhp6eHQYMG4enTp+jatStCQ0Ohq6tZEqoQQgjtnBZR2aWmpsLCwgIpKVdhbm724h2IZGhkQ+fKDoGoQmTlCoT+lYOUlBSVyf7aVPA98Xj/QJib6Jevr4xs1Oj63wqNt6Kw4kZEREQyoo05avKd4i/fyImIiIiqGVbciIiISD4UivJX3DS8d1pVwsSNiIiI5EMbt/PQ4u1AXjb5Rk5ERERUzbDiRkRERPJRzStuTNyIiIhIPqp54ibfyImIiIiqGVbciIiISD6qecWNiRsRERHJBxM3IiIiIpmo5ombfCMnIiIiqmZYcSMiIiL5qOYVNyZuREREJB/VPHGTb+RERERE1QwrbkRERCQffMg8ERERkUxwqJSIiIiI5IAVNyIiIpKPal5xY+JGRERE8qHQzV/K24dMyTflJCIiIqpmWHEjIiIi+eBQKREREZFMMHEjIiIikolqnrjJN3IiIiKiaoYVNyIiIpKPal5xY+JGREREMqKFR15Bvo+8km/KSURERFTNsOJGRERE8sGhUiIiIiKZqOaJm3wjJyIiIqpmWHEjIiIi+ajmFTcmbkRERCQf1Txxk2/kRERERNWMLBO30NBQ1KhRo8r0U9Wpc57+/v7o16/fS4mHXo6dK5djzgBvfNqyGSa2b4PlH3+IpL9ulth+3fQvMLKhC/aFrnmJURKpr9fIUZj6xxYsPXsJ35yIwcfLf4KtSz1pu46eHgZM/Bwztu7Cd7FXMP/IKfgvWAgLGxupTc3adfDj9VvFLq169a6M0yJNFVTcyrvIVJWN3MXFBbt27dJaf87OzliyZInKusGDB+P69etaO0ZVUNx5qmPp0qUIDQ19YTuFQoHNmzdr3D+9fNejT8Hjvffx+W8bMTbkF+Tl5mJpwAfIfPKkSNvYvXsQfz4WNWxsKyFSIvU0dG+HQ+vWYt6g/lg67H3o6Opi7JpfYGBkBAAwMDSCY9Om2L58GWb374uVoz+CrXM9fLJildTHv4n3Mamju8oSuXQRnmVk4PLhQ5V0ZqSRSkjcnJ2doVAoiiyffPIJgPziR+Ft7du3r4izr1pz3LKysmBgYIALFy4gOTkZXbp0qdDjGRkZwej/f+HlruBnV1YWFhYV2j+9fGNXh6m89pu3ABPbt8HtyxfR0L2dtP5RUhJ+nRWEsWvC8P2HAS87TCK1fTfcT+V12OeTsPDUWTg1dcONmNN4lp6GpcPeV2mz/qsgfPFHJCztHfAo8T5EXh5S/3mo0qZF956I2bGt2D9qqAqqhDlu0dHRyM3NlV5funQJ3bt3x7vvviut69WrF0JCQqTXFfWdWakVNw8PD4wePRrjx4+HtbU1unfvDgDYsmULevbsCaVSCSB/qK9u3bowNjZG//79kZycrNLPzZs34e3tDVtbW5iamsLd3R379u1TOc7t27fx2WefSZlwQb/PDyEGBwejRYsWWLt2LZydnWFhYQEfHx+kpaVJbdLS0uDr6wsTExPY29tj8eLF8PDwwLhx46Q2jx49wgcffABLS0sYGxvD09MTN27cAACkpKTAyMioSDVx48aNMDExQXp6OgDg3r17GDx4MCwtLVGzZk14e3vj1q1bUvuCoc25c+fCwcEBDRs2LPE8C+zevRuNGzeGqakpevXqhcTExCL9lfbeODs7AwD69+8PhUIBZ2dn3Lp1Czo6OoiJiVE51rJly+Dk5AQhBKhqePr/n2MTixrSury8PIRMHo8ewz+EQ4OGlRQZUdkYmZkBADJSHpfaJi8vD09TU4vdXrdpM9Rt0hTH/ruhIkKkV0StWrVgZ2cnLdu2bYOrqys6d+4stVEqlSptrKysKiSWSh8qDQsLg56eHo4dO4Yff/wRABAZGQlvb28AwKlTpxAQEIBRo0YhNjYWXbp0wddff63SR3p6Onr37o19+/bh3Llz6NmzJ7y8vHDnzh0A+UlRnTp1MGvWLCQmJqokLIXdvHkTmzdvxrZt27Bt2zZERUVh3rx50vbx48fj2LFjiIyMxN69e3HkyBGcPXtWpQ9/f3/ExMQgMjISJ06cgBACvXv3RnZ2NiwsLNCnTx+Eh4er7BMREQFvb2+YmpriyZMn6NKlC0xNTXH48GEcPXpUSraysrKkffbv34+4uDjs3bsX27ZtK/U8nzx5gm+//RZr167F4cOHcefOHUycOFGj9yY6OhoAEBISgsTERERHR8PZ2RndunVT+SujoE1B6bg4mZmZSE1NVVmo4ggh8Pvcr1G/dRvUbthIWr/7p5XQ0dXFWx/4V15wRGX07tQvcSPmNO7fKH7Ki56BEgMmTEH01i14lpFebJtOAwfj/p838Ne5s8VupypIi0Olhb+HMjMzX3j4rKwsrFu3DgEBASrfcYcOHYKNjQ0aNmyIESNG4MGDBxVy+pU+VFq/fn0sWLBAen3v3j2cP38evXvnTxJdunQpevbsic8//xwA0LBhQxw/flylYtW8eXM0b95cev31119j06ZNiIyMxOjRo2FlZQVdXV2YmZnBzs6u1Hjy8vIQGhoKs///S+7999/H/v37MXv2bKSlpSEsLAwRERHo2rUrgPwExcHBQdr/xo0biIyMxLFjx9CxY0cAQHh4OBwdHbF582a8++678PX1xQcffIAnT57A2NgYqamp2L59O/744w8AwPr166Gjo4NVq1ZJH4qQkBDUqFEDhw4dQo8ePQAAJiYmWLVqlUo5tqTzzM7OxsqVK+Hq6goAGD16NGbNmqXRe1OgRo0aKv0PHz4cH330ERYtWgSlUonz588jNjYWGzduLLHvuXPnYubMmaUen7Tn15kzcO/aVUz69Xdp3e1LF3HglxBM27StxASbqKoaEjQLtRs1xjdDBha7XUdPDyOWLINCRwcRwdOLbaOvVKKtlze2L/+uIkMlrVOg/HWn/H/zHB0dVdYGBQUhODi41D03b96Mx48fw9/fX1rn6emJd999F05OToiPj8f06dPx1ltv4cyZM9LoobZUesWtTZs2Kq8jIyPRqVMnqcQYFxeHDh06qLQp/DojIwOTJ09GkyZNUKNGDZiamuLq1atSxU0Tzs7OUtIGAPb29lLW/NdffyE7Oxtt27aVtltYWKBRo/9VMOLi4qCnp4d27f43h6hmzZpo1KgR4uLiAAB9+vSBnp4eIiMjAQB//PEHzMzMpITszJkz+PPPP2FmZgZTU1OYmprCysoKz549w82b/7sq0M3NTe0xdGNjYylpK3xeJSn83pSkX79+0NPTw6ZNmwAAa9asQZcuXaSh1eJMnToVKSkp0pKQkKDWsUhzv84KwoUD+zH+l19haWcvrb8RE4205GRM9eiEjxvXx8eN6yP53j38d95sfNHljUqMmKh0PtOD8fpb3bDoAx88/jupyHYdPT18uPQH1KzjiCXD3iux2taqV28YGBri5KaS/8ikV1tCQoLKd9HUqVNfuM/q1avh6empUrQZPHgw+vTpg2bNmsHLyws7d+7E9evXsX37dq3HXOkVNxMTE5XXzw+TAlBrjtSkSZOwe/dufPvtt6hfvz6MjIwwcOBAlWFFdenr66u8VigUyMvLU4mlcHXi+RhLilcIIe1nYGCAgQMHIiIiAj4+PoiIiMDgwYOhp5f/duTl5aF169ZFhlOB/HH2AoV/dpqe14t+tur2b2BggPfffx8hISEYMGAAIiIiXnhlq1Kp1PpfIaRKCIH1s4IQu3cPxq/7FdaF/rJs790fjTt2Uln3XYAf2nn3R8d3iq9iEFU2nxkz0aJ7Tyx6zwfJd+8W2V6QtNk4OWPR+0OQ8fhxiX11GjgY5w/sQ/qjfyswYtI6hSJ/KW8fAMzNzWFubq72brdv38a+fftKHVEC8osjTk5O0vx2bar0xO156enpOHjwIH744QdpXZMmTXDy5EmVdoVfHzlyBP7+/ujfv7/Uz/MT+YH85OL5K0LKwtXVFfr6+jh9+rRUXk1NTcWNGzekCYpNmjRBTk4OTp06JQ2VJicn4/r162jcuLHUl6+vL3r06IHLly/j4MGD+Oqrr6RtrVq1woYNG2BjY6PRB0pb51kafX39YvsfPnw4mjVrhuXLlyM7OxsDBgyosBhIPb/OnIHTW7dg1IqfYGhiipSH+VfSGZmZwcDQEKaWljC1tFTZR1dfD+a1asGunmtxXRJVqiFBX6GtlzeWfzwCzzIyYG6d/4fs07RUZGdmQkdXFyO/W4G6TZvih5GB0NHVldpkpDxGbna21Fetuk5o4N4W348YVinnQuVQiU9OCAkJgY2NDfr06VNqu+TkZCQkJMDe3r7UdmVR6UOlz9u1axcaNGiAevX+d0PFTz/9FLt27cKCBQtw/fp1fP/990WuyKxfvz42btyI2NhYnD9/HkOHDpWqZAWcnZ1x+PBh3Lt3D//880+Z4jMzM4Ofnx8mTZqEgwcP4vLlywgICICOjo5UTWvQoAG8vb0xYsQIHD16FOfPn8d7772H2rVrq1QSO3fuDFtbW/j6+sLZ2Vnlfi++vr6wtraGt7c3jhw5gvj4eERFRWHs2LG4W8xfmNo+zxf1v3//fiQlJeHRo0fS+saNG6N9+/aYMmUKhgwZ8srcZkXOoiLW4WlaGha+NwSTO7WVlpgd2yo7NKIy8fB9H8bm5pgYvgHfHI+Wlja9vQAAlnb2aNGtO6zsHTA9cqdKG9eWrVX66jRwEB7/nYQrRw9XxqmQDOXl5SEkJAR+fn7SCBmQXyyaOHEiTpw4gVu3buHQoUPw8vKCtbW1VFDSpipVcduyZYtKcgMA7du3x6pVq6QJg926dcOXX36pUqFavHgxAgIC0LFjR1hbW2PKlClFrlKcNWsWRo4cCVdXV2RmZpb5NhWLFi3CRx99hL59+8Lc3ByTJ09GQkICDA0NpTYhISEYO3Ys+vbti6ysLLz55pvYsWOHynClQqHAkCFD8M0332DGjBkqxzA2Nsbhw4cxZcoUDBgwAGlpaahduza6du36wgqcts6zJAsXLsT48ePx888/o3bt2iqVzcDAQBw/fhwBAbwXWFXw4/V4jfeZc/BoBURCpB0jGzqXuj353t0XtimwedE32Lzom/IHRZVAgYKLC8rXh2b27duHO3fuFPmO09XVxcWLF/HLL7/g8ePHsLe3R5cuXbBhwwaVOfPaohBV5EZbubm5sLGxwc6dO1Um/1d1GRkZqF27NhYuXIjAwMDKDqdSzZ49G+vXr8fFixc13jc1NRUWFhZISbkKc3Ptf9CJqgJ1kwoiucnKFQj9KwcpKSkaT/FRV8H3xONri2BuVr5RndS0p6jRaHyFxltRqkzFLTk5GZ999hnc3d0rO5RSnTt3DlevXkXbtm2RkpIi3VKjcKWwOklPT0dcXByWLVumUgklIiIi7aoyc9xsbGzw5ZdfyuJ+Ut9++y2aN2+Obt26ISMjA0eOHIG1tXVlh1VpRo8ejTfeeAOdO3fmMCkREVWsav6Q+SpTcZOLli1b4syZM5UdRpUSGhqq1gPqiYiIyq9y5rhVFUzciIiISD60eB83OZJvrZCIiIiommHFjYiIiGREB+WvO8m3bsXEjYiIiOSDQ6VEREREJAesuBEREZF8VOKzSqsCJm5EREQkI9X7diDyTTmJiIiIqhlW3IiIiEg+qvnFCUzciIiISD4UCi3McZNv4sahUiIiIiKZYMWNiIiIZKR6X5zAxI2IiIhkRAtz3Ji4EREREVU8hUIHinLOcSvv/pVJvpETERERVTOsuBEREZGMcI4bERERkTxU8/u4caiUiIiISCZYcSMiIiIZ0UH5607yrVsxcSMiIiL54FApEREREckBK25EREQkH9W84sbEjYiIiGSkes9xk2/kRERERNUMK25EREQkHxwqJSIiIpIJJm5EREREcsE5bkREREQkA6y4ERERkXxwqJSIiIhILhT/v5S3D3niUCkRERGRTDBxIyIiIvlQKACFTjkX9StuwcHBUCgUKoudnZ20XQiB4OBgODg4wMjICB4eHrh8+XJFnDkAJm5EREQkJwVz3Mq7aKBp06ZITEyUlosXL0rbFixYgEWLFuH7779HdHQ07Ozs0L17d6SlpWn7zAEwcSMiIiIqlZ6eHuzs7KSlVq1aAPKrbUuWLMG0adMwYMAANGvWDGFhYXjy5AkiIiIqJBYmbkRERCQjCi0tQGpqqsqSmZlZ7BFv3LgBBwcHuLi4wMfHB3/99RcAID4+HklJSejRo4fUVqlUonPnzjh+/LjWzxxg4kZERERyUu75bf+/AHB0dISFhYW0zJ07t8jh2rVrh19++QW7d+/Gzz//jKSkJHTs2BHJyclISkoCANja2qrsY2trK23TNt4OhIiIiKqlhIQEmJubS6+VSmWRNp6entL/u7m5oUOHDnB1dUVYWBjat28PAFAUmjMnhCiyTltYcSMiIiIZ0d5Qqbm5ucpSXOJWmImJCdzc3HDjxg3p6tLC1bUHDx4UqcJpCxM3IiIikhHtJW5lkZmZibi4ONjb28PFxQV2dnbYu3evtD0rKwtRUVHo2LFjmY9RGg6VEhERkXw8N0etXH2oaeLEifDy8kLdunXx4MEDfP3110hNTYWfnx8UCgXGjRuHOXPmoEGDBmjQoAHmzJkDY2NjDB06tHwxloCJGxEREVEJ7t69iyFDhuCff/5BrVq10L59e5w8eRJOTk4AgMmTJ+Pp06cYNWoUHj16hHbt2mHPnj0wMzOrkHiYuBEREZGMvNxnla5fv770nhQKBAcHIzg4uJwxqYeJGxEREckIHzJPRERERDLAihsRERHJiA7KX3eSb92KiRsRERHJRxkeEl9sHzIl35STiIiIqJphxY2IiIhkpHpfnMDEjYiIiGSkeiduHColIiIikglW3IiIiEhGFCh/3Um+FTcmbkRERCQf1fyqUiZuREREJCOc40ZEREREMsCKGxEREckIn5xAREREJBMcKiUiIiIiGWDFjYiIiOSDV5USERERyQWHSomIiIhIBlhxIyIiIhnhVaVEREREMsGhUiIiIiKSAVbciIiISD54VSkRERGRXHCOGxEREZFMcI4bEREREckAK25EREQkI9W74sbEjYiIiOSjml+cwKFSIiIiIplgxY2IiIhkRIHy153kW3Fj4kZEREQyUr3nuHGolIiIiEgmWHEjIiIiGaneFTcmbkRERCQfCp38pbx9yJR8IyciIiKqZlhxIyIiIhmp3kOlrLgRERGRjCi0tKhn7ty5cHd3h5mZGWxsbNCvXz9cu3ZNpY2/vz8UCoXK0r59+3KeZ/GYuBEREZGMvNzELSoqCp988glOnjyJvXv3IicnBz169EBGRoZKu169eiExMVFaduzYUc7zLB6HSomIiIhKsGvXLpXXISEhsLGxwZkzZ/Dmm29K65VKJezs7Co8HlbciIiISD4Kriot7wIgNTVVZcnMzHzh4VNSUgAAVlZWKusPHToEGxsbNGzYECNGjMCDBw+0f+5g4kZERESyor2hUkdHR1hYWEjL3LlzSz2yEALjx4/HG2+8gWbNmknrPT09ER4ejgMHDmDhwoWIjo7GW2+9pVYiqCkOlVKVIIQAAKSmpldyJEQVJytXVHYIRBUiKy//s13wb3lFSk1N01ofCQkJMDc3l9YrlcpS9xs9ejQuXLiAo0ePqqwfPHiw9P/NmjVDmzZt4OTkhO3bt2PAgAHljvd5TNyoSkhLy/8lcnRsU8mREBFRWaWlpcHCwqJC+jYwMICdnR0cHd210p+dnR2sra1haGioVvsxY8YgMjIShw8fRp06dUpta29vDycnJ9y4cUMboapg4kZVgoODAxISEmBmZgaFQr7315GL1NRUODo6Fvlrk+hVwc/4yyWEQFpaGhwcHCrsGIaGhoiPj0dWVpZW+jMwMFAraRNCYMyYMdi0aRMOHToEFxeXF+6TnJyMhIQE2NvbayNUFQrxMuqaRFSlpKamwsLCAikpKfxSo1cSP+OkLaNGjUJERAS2bNmCRo0aSestLCxgZGSE9PR0BAcH45133oG9vT1u3bqFL774Anfu3EFcXBzMzMy0Gg8TN6JqiF9q9KrjZ5y0paRRoJCQEPj7++Pp06fo168fzp07h8ePH8Pe3h5dunTBV199BUdHR63Hw6FSIiIiohK8qL5lZGSE3bt3v6RoeDsQompJqVQiKCjohVdQEckVP+P0quJQKREREZFMsOJGREREJBNM3IiIiIhkgokbERERkUwwcSN6RYSGhqJGjRpVph96NfBzpRl1ztPf3x/9+vV7KfHQq4eJG5GMuLi4YNeuXVrrz9nZGUuWLFFZN3jwYFy/fl1rx6Cqj5+rsinuPNWxdOlShIaGvrCdQqHA5s2bNe6fXm28jxtRFZeVlQUDAwNcuHABycnJ6NKlS4Uez8jICEZGRhV6DKp8/FyVXcHPrqxe9CzP8vZPrzZW3IiqGA8PD4wePRrjx4+HtbU1unfvDgDYsmULevbsKd2XKjQ0FHXr1oWxsTH69++P5ORklX5u3rwJb29v2NrawtTUFO7u7ti3b5/KcW7fvo3PPvsMCoVCujt44aGe4OBgtGjRAmvXroWzszMsLCzg4+ODtLQ0qU1aWhp8fX1hYmICe3t7LF68GB4eHhg3blwF/ZRIU6/q5+rRo0f44IMPYGlpCWNjY3h6ekoP9k5JSYGRkVGRauLGjRthYmKC9PR0AMC9e/cwePBgWFpaombNmvD29satW7ek9gVDm3PnzoWDgwMaNmxY4nkW2L17Nxo3bgxTU1P06tULiYmJRfor7b1xdnYGAPTv3x8KhQLOzs64desWdHR0EBMTo3KsZcuWwcnJ6YU3iqVXAxM3oiooLCwMenp6OHbsGH788UcAQGRkJLy9vQEAp06dQkBAAEaNGoXY2Fh06dIFX3/9tUof6enp6N27N/bt24dz586hZ8+e8PLywp07dwDkf3nVqVMHs2bNQmJiosoXS2E3b97E5s2bsW3bNmzbtg1RUVGYN2+etH38+PE4duwYIiMjsXfvXhw5cgRnz57V9o+FyulV/Fz5+/sjJiYGkZGROHHiBIQQ6N27N7Kzs2FhYYE+ffogPDxcZZ+IiAh4e3vD1NQUT548QZcuXWBqaorDhw/j6NGjUrL1/MPM9+/fj7i4OOzduxfbtm0r9TyfPHmCb7/9FmvXrsXhw4dx584dTJw4UaP3Jjo6GkD+Y5USExMRHR0NZ2dndOvWDSEhISr7Fjx6qaRHM9ErRhBRldK5c2fRokULlXV3794V+vr6Ijk5WQghxJAhQ0SvXr1U2gwePFhYWFiU2neTJk3EsmXLpNdOTk5i8eLFKm1CQkJU+gkKChLGxsYiNTVVWjdp0iTRrl07IYQQqampQl9fX/z+++/S9sePHwtjY2MxduzYF50uvSSv4ufq+vXrAoA4duyY1Oaff/4RRkZG4rfffhNCCLFx40ZhamoqMjIyhBBCpKSkCENDQ7F9+3YhhBCrV68WjRo1Enl5eVIfmZmZwsjISOzevVsIIYSfn5+wtbUVmZmZKudU0nkCEH/++ae07ocffhC2trbSaz8/P+Ht7S29Lu69EUIIAGLTpk0q6zZs2CAsLS3Fs2fPhBBCxMbGCoVCIeLj44vsT68mVtyIqqA2bdqovI6MjESnTp1gZWUFAIiLi0OHDh1U2hR+nZGRgcmTJ6NJkyaoUaMGTE1NcfXqVakyoglnZ2eYmZlJr+3t7fHgwQMAwF9//YXs7Gy0bdtW2m5hYYFGjRppfByqWK/a5youLg56enpo166dtK5mzZpo1KgR4uLiAAB9+vSBnp4eIiMjAQB//PEHzMzM0KNHDwDAmTNn8Oeff8LMzAympqYwNTWFlZUVnj17hps3b0r9urm5qT3vzNjYGK6ursWeV0kKvzcl6devH/T09LBp0yYAwJo1a9ClSxdpaJVefbw4gagKMjExUXn9/HAW8OKHHgPApEmTsHv3bnz77beoX78+jIyMMHDgQJXhH3Xp6+urvFYoFMjLy1OJpfAwjTox0sv1qn2uSopXCCHtZ2BggIEDByIiIgI+Pj6IiIjA4MGDoaeX//WXl5eH1q1bFxlOBYBatWpJ/1/4Z6fpeb3oZ6tu/wYGBnj//fcREhKCAQMGICIiokxXtpJ8seJGVMWlp6fj4MGDePvtt6V1TZo0wcmTJ1XaFX595MgR+Pv7o3///nBzc4OdnZ3KhGsg/0sgNze3XPG5urpCX18fp0+fltalpqZKE8SpanoVPldNmjRBTk4OTp06Ja1LTk7G9evX0bhxY2mdr68vdu3ahcuXL+PgwYPw9fWVtrVq1Qo3btyAjY0N6tevr7K86OpPbZxnafT19Yvtf/jw4di3bx+WL1+O7OxsDBgwoMJioKqHiRtRFbdr1y40aNAA9erVk9Z9+umn2LVrFxYsWIDr16/j+++/L3LlXP369bFx40bExsbi/PnzGDp0qFTNKODs7IzDhw/j3r17+Oeff8oUn5mZGfz8/DBp0iQcPHgQly9fRkBAAHR0dDhZugp7FT5XDRo0gLe3N0aMGIGjR4/i/PnzeO+991C7dm2VSmLnzp1ha2sLX19fODs7o3379tI2X19fWFtbw9vbG0eOHEF8fDyioqIwduxY3L17t9QYtXGeL+p///79SEpKwqNHj6T1jRs3Rvv27TFlyhQMGTLklbnNCqmHiRtRFbdlyxaVLyEAaN++PVatWoVly5ahRYsW2LNnD7788kuVNosXL4alpSU6duwILy8v9OzZE61atVJpM2vWLNy6dQuurq4qw0KaWrRoETp06IC+ffuiW7du6NSpExo3bgxDQ8My90kV61X5XIWEhKB169bo27cvOnToACEEduzYoTJcqVAoMGTIEJw/f16l2gbkz0c7fPgw6tatiwEDBqBx48YICAjA06dPYW5uXmp82jrPkixcuBB79+6Fo6MjWrZsqbItMDAQWVlZCAgI0PpxqWpTCE5EIaqycnNzYWNjg507d6pM0q7qMjIyULt2bSxcuBCBgYGVHQ4Vws+V/M2ePRvr16/HxYsXKzsUesl4cQJRFZacnIzPPvsM7u7ulR1Kqc6dO4erV6+ibdu2SElJwaxZswCgSEWHqgZ+ruQrPT0dcXFxWLZsGb766qvKDocqAStuRFRu586dw/Dhw3Ht2jUYGBigdevWWLRoEdzc3Co7NJIxfq6K8vf3x6+//op+/fohIiICurq6lR0SvWRM3IiIiIhkghcnEBEREckEEzciIiIimWDiRkRERCQTTNyIiIiIZIKJGxHR/wsODkaLFi2k1/7+/ujXr99Lj+PWrVtQKBSIjY0tsY2zs7NGz6gMDQ1FjRo1yh2bQqHA5s2by90PEZUNEzciqtL8/f2hUCigUCigr6+PevXqYeLEicjIyKjwYy9duhShoaFqtVUn2SIiKi/egJeIqrxevXohJCQE2dnZOHLkCIYPH46MjAysWLGiSNvs7GyVxx2Vx4seMk5E9LKx4kZEVZ5SqYSdnR0cHR0xdOhQ+Pr6SsN1BcOba9asQb169aBUKiGEQEpKCj788EPY2NjA3Nwcb731Fs6fP6/S77x582BrawszMzMEBgbi2bNnKtsLD5Xm5eVh/vz5qF+/PpRKJerWrYvZs2cDAFxcXAAALVu2hEKhgIeHh7RfSEiI9IzN1157DcuXL1c5zunTp9GyZUsYGhqiTZs2OHfunMY/o4Ib05qYmMDR0RGjRo1Cenp6kXabN29Gw4YNYWhoiO7duyMhIUFl+9atW9G6dWsYGhqiXr16mDlzJnJycjSOh4gqBhM3IpIdIyMjZGdnS6///PNP/Pbbb/jjjz+koco+ffogKSkJO3bswJkzZ9CqVSt07doV//77LwDgt99+Q1BQEGbPno2YmBjY29sXSagKmzp1KubPn4/p06fjypUriIiIgK2tLYD85AsA9u3bh8TERGzcuBEA8PPPP2PatGmYPXs24uLiMGfOHEyfPh1hYWEA8p+/2bdvXzRq1AhnzpxBcHAwJk6cqPHPREdHB9999x0uXbqEsLAwHDhwAJMnT1Zp8+TJE8yePRthYWE4duwYUlNT4ePjI23fvXs33nvvPXz66ae4cuUKfvzxR4SGhkrJKRFVAYKIqArz8/MT3t7e0utTp06JmjVrikGDBgkhhAgKChL6+vriwYMHUpv9+/cLc3Nz8ezZM5W+XF1dxY8//iiEEKJDhw7io48+Utnerl070bx582KPnZqaKpRKpfj555+LjTM+Pl4AEOfOnVNZ7+joKCIiIlTWffXVV6JDhw5CCCF+/PFHYWVlJTIyMqTtK1asKLav5zk5OYnFixeXuP23334TNWvWlF6HhIQIAOLkyZPSuri4OAFAnDp1SgghxH/+8x8xZ84clX7Wrl0r7O3tpdcAxKZNm0o8LhFVLM5xI6Iqb9u2bTA1NUVOTg6ys7Ph7e2NZcuWSdudnJxQq1Yt6fWZM2eQnp6OmjVrqvTz9OlT3Lx5EwAQFxeHjz76SGV7hw4dcPDgwWJjiIuLQ2ZmJrp27ap23A8fPkRCQgICAwMxYsQIaX1OTo40fy4uLg7NmzeHsbGxShyaOnjwIObMmYMrV64gNTUVOTk5ePbsGTIyMmBiYgIA0NPTQ5s2baR9XnvtNdSoUQNxcXFo27Ytzpw5g+joaJUKW25uLp49e4YnT56oxEhElYOJGxFVeV26dMGKFSugr68PBweHIhcfFCQmBfLy8mBvb49Dhw4V6aust8QwMjLSeJ+8vDwA+cOl7dq1U9lW8HBwoYXHRd++fRu9e/fGRx99hK+++gpWVlY4evQoAgMDVYaUgfzbeRRWsC4vLw8zZ87EgAEDirQxNDQsd5xEVH5M3IioyjMxMUH9+vXVbt+qVSskJSVBT08Pzs7OxbZp3LgxTp48iQ8++EBad/LkyRL7bNCgAYyMjLB//34MHz68yHYDAwMA+RWqAra2tqhduzb++usv+Pr6FttvkyZNsHbtWjx9+lRKDkuLozgxMTHIycnBwoULoaOTP3X5t99+K9IuJycHMTExaNu2LQDg2rVrePz4MV577TUA+T+3a9euafSzJqKXi4kbEb1yunXrhg4dOqBfv36YP38+GjVqhPv372PHjh3o168f2rRpg7Fjx8LPzw9t2rTBG2+8gfDwcFy+fBn16tUrtk9DQ0NMmTIFkydPhoGBATp16oSHDx/i8uXLCAwMhI2NDYyMjLBr1y7UqVMHhoaGsLCwQHBwMD799FOYm5vD09MTmZmZiImJwaNHjzB+/HgMHToU06ZNQ2BgIL788kvcunUL3377rUbn6+rqipycHCxbtgxeXl44duwYVq5cWaSdvr4+xowZg++++w76+voYPXo02rdvLyVyM2bMQN++feHo6Ih3330XOjo6uHDhAi5evIivv/5a8zeCiLSOV5US0StHoVBgx44dePPNNxEQEICGDRvCx8cHt27dkq4CHTx4MGbMmIEpU6agdevWuH37Nj7++ONS+50+fTomTJiAGTNmoHHjxhg8eDAePHgAIH/+2HfffYcff/wRDg4O8Pb2BgAMHz4cq1atQmhoKNzc3NC5c2eEhoZKtw8xNTXF1q1bceXKFbRs2RLTpk3D/PnzNTrfFi1aYNGiRZg/fz6aNWuG8PBwzJ07t0g7Y2NjTJkyBUOHDkWHDh1gZGSE9evXS9t79uyJbdu2Ye/evXB3d0f79u2xaNEiODk5aRQPEVUchdDGBAsiIiIiqnCsuBERERHJBBM3IiIiIplg4kZEREQkE0zciIiIiGSCiRsRERGRTDBxIyIiIpIJJm5EREREMsHEjYiIiEgmmLgRERERyQQTNyIiIiKZYOJGREREJBNM3IiIiIhk4v8AJMIP5Wccgq4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/4sqt0lt90t72lgqr2zq3p6l80000gn/T/ipykernel_33031/2230439169.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_performance_capture = model_performance_capture.append(model_evaluation(rs2, 'Model_2_RsCV_Multi_CVEC'))\n"
     ]
    }
   ],
   "source": [
    "model_performance_capture = model_performance_capture.append(model_evaluation(rs2, 'Model_2_RsCV_Multi_CVEC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ee78a-6b5a-42f2-aeda-975e77901061",
   "metadata": {},
   "source": [
    "## Tree-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c3a21-ef1f-470d-b8be-fb46e766c058",
   "metadata": {},
   "source": [
    "### 03 - Bagged Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46161a84-ea49-4b67-bd0f-47241641916d",
   "metadata": {},
   "source": [
    "#### Pipeline and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "becd9a4c-8836-48ff-a312-35e957226203",
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {\n",
    "     'tvec__preprocessor': [None                            #Best Fit V1\n",
    "                            # ,stem_post\n",
    "                            ,lemmatize_post\n",
    "                           ],\n",
    "     'tvec__max_df': np.linspace(0.75, 0.95,6),               #0.9 on [1, 0.9] V1\n",
    "     'tvec__max_features': [4000, 5000, 6000], #5000 on [None, 5000] V1\n",
    "     'tvec__min_df': [1],\n",
    "     'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tvec__stop_words': ['english'],                #english best in V1 [None, 'english']\n",
    "     \n",
    "    'bag__estimator__max_depth': np.arange(8,11,1),  #10 on V1\n",
    "     'bag__estimator__min_samples_leaf': np.arange(1, 4, 1), # 1 in V1\n",
    "     'bag__n_estimators': [200]\n",
    "}\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('bag', BaggingClassifier(tree))\n",
    "])\n",
    "\n",
    "rs3 = RandomizedSearchCV(estimator=pipe3, \n",
    "                         param_distributions=params3, \n",
    "                         cv = 5, \n",
    "                         n_iter = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746825c3-55bd-40b1-8624-d177baa05d2f",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "4dc73be2-492c-4b22-ae7a-93290f6137f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;tvec&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;bag&#x27;,\n",
       "                                              BaggingClassifier(estimator=DecisionTreeClassifier()))]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions={&#x27;bag__estimator__max_depth&#x27;: array([ 8,  9, 10]),\n",
       "                                        &#x27;bag__estimator__min_samples_leaf&#x27;: array([1, 2, 3]),\n",
       "                                        &#x27;bag__n_estimators&#x27;: [200],\n",
       "                                        &#x27;tvec__max_df&#x27;: array([0.75, 0.79, 0.83, 0.87, 0.91, 0.95]),\n",
       "                                        &#x27;tvec__max_features&#x27;: [4000, 5000,\n",
       "                                                               6000],\n",
       "                                        &#x27;tvec__min_df&#x27;: [1],\n",
       "                                        &#x27;tvec__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                                        &#x27;tvec__preprocessor&#x27;: [None,\n",
       "                                                               &lt;function lemmatize_post at 0x7fbf28e23a30&gt;],\n",
       "                                        &#x27;tvec__stop_words&#x27;: [&#x27;english&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;tvec&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;bag&#x27;,\n",
       "                                              BaggingClassifier(estimator=DecisionTreeClassifier()))]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions={&#x27;bag__estimator__max_depth&#x27;: array([ 8,  9, 10]),\n",
       "                                        &#x27;bag__estimator__min_samples_leaf&#x27;: array([1, 2, 3]),\n",
       "                                        &#x27;bag__n_estimators&#x27;: [200],\n",
       "                                        &#x27;tvec__max_df&#x27;: array([0.75, 0.79, 0.83, 0.87, 0.91, 0.95]),\n",
       "                                        &#x27;tvec__max_features&#x27;: [4000, 5000,\n",
       "                                                               6000],\n",
       "                                        &#x27;tvec__min_df&#x27;: [1],\n",
       "                                        &#x27;tvec__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                                        &#x27;tvec__preprocessor&#x27;: [None,\n",
       "                                                               &lt;function lemmatize_post at 0x7fbf28e23a30&gt;],\n",
       "                                        &#x27;tvec__stop_words&#x27;: [&#x27;english&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tvec&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;bag&#x27;, BaggingClassifier(estimator=DecisionTreeClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">bag: BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" ><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                             ('bag',\n",
       "                                              BaggingClassifier(estimator=DecisionTreeClassifier()))]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions={'bag__estimator__max_depth': array([ 8,  9, 10]),\n",
       "                                        'bag__estimator__min_samples_leaf': array([1, 2, 3]),\n",
       "                                        'bag__n_estimators': [200],\n",
       "                                        'tvec__max_df': array([0.75, 0.79, 0.83, 0.87, 0.91, 0.95]),\n",
       "                                        'tvec__max_features': [4000, 5000,\n",
       "                                                               6000],\n",
       "                                        'tvec__min_df': [1],\n",
       "                                        'tvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                                        'tvec__preprocessor': [None,\n",
       "                                                               <function lemmatize_post at 0x7fbf28e23a30>],\n",
       "                                        'tvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3.fit(X_train, y_train)\n",
    "# pickle.dump(rs3, open('./pickled_models/rs3_bagged_trees.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9844a7-fd53-4164-bb7a-7e69903ca786",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "1aa572cb-6338-4f09-a200-093d3c7da77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Accuracy Scores:\n",
      "  Train: 0.94993 \n",
      "  Test: 0.76471\n",
      "  Baseline: 0.50913\n",
      "---\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7480    0.7851    0.7661       242\n",
      "           1     0.7824    0.7450    0.7633       251\n",
      "\n",
      "    accuracy                         0.7647       493\n",
      "   macro avg     0.7652    0.7651    0.7647       493\n",
      "weighted avg     0.7655    0.7647    0.7647       493\n",
      "\n",
      "\n",
      "---\n",
      "Best Parameters: \n",
      "{'tvec__stop_words': 'english', 'tvec__preprocessor': None, 'tvec__ngram_range': (1, 1), 'tvec__min_df': 1, 'tvec__max_features': 6000, 'tvec__max_df': 0.95, 'bag__n_estimators': 200, 'bag__estimator__min_samples_leaf': 1, 'bag__estimator__max_depth': 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/4sqt0lt90t72lgqr2zq3p6l80000gn/T/ipykernel_33031/1974463261.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_performance_capture = model_performance_capture.append(model_evaluation(rs3, 'Model_3_Bagged_Trees'))\n"
     ]
    }
   ],
   "source": [
    "model_performance_capture = model_performance_capture.append(model_evaluation(rs3, 'Model_3_Bagged_Trees'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ef965-d9b3-44cb-a21b-7cfad5bda13b",
   "metadata": {},
   "source": [
    "### 04 - RandomForest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f3dc0-a339-4495-9bc8-c5b078a99b77",
   "metadata": {},
   "source": [
    "#### Pipeline and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "5aecea7f-6b25-4c38-9c5e-d63ee8386855",
   "metadata": {},
   "outputs": [],
   "source": [
    "params4 = {\n",
    "    'tvec__preprocessor': [None, lemmatize_post],\n",
    "     'tvec__max_df': np.linspace(0.75, 0.95,6),              \n",
    "     'tvec__max_features': [4000, 5000, 6000],\n",
    "     'tvec__min_df': [1],\n",
    "     'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tvec__stop_words': ['english'],       \n",
    "    \n",
    "     'rfc__max_depth': [10,20],\n",
    "     'rfc__min_samples_split': [2,4,8],\n",
    "     'rfc__n_estimators': [100],\n",
    "     'rfc__random_state': [2187]\n",
    "}\n",
    "\n",
    "pipe4 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('rfc', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "rs4 = RandomizedSearchCV(estimator=pipe4, \n",
    "                         param_distributions=params4, \n",
    "                         n_iter = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e61502-0cba-4252-a88f-4a879de255ea",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60098ba6-6b02-48f1-a3f1-963270a076a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/robertadams/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rs4.fit(X_train, y_train)\n",
    "# pickle.dump(rs4, open('./pickled_models/rs4_Random_Forest.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069793dd-f495-4fc8-8584-a8c5c740ae22",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc69f3-0adf-4299-855a-eab116adb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_capture = model_performance_capture.append(model_evaluation(rs4, 'Model_4_Random_Forrest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6e51d-71f1-4507-a263-6652ef6331d2",
   "metadata": {},
   "source": [
    "### 05 - Boosted Trees with AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f728d-3a61-4c38-82f9-0c57c7ea97c6",
   "metadata": {},
   "source": [
    "#### Pipeline and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf29a38-e8c8-454b-94a2-d653ad8eac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "params5 = {\n",
    "     'tvec__preprocessor': [None,lemmatize_post],\n",
    "     'tvec__max_df': np.linspace(0.75, 0.95,6),              \n",
    "     'tvec__max_features': [4000, 5000, 6000], \n",
    "     'tvec__min_df': [1],\n",
    "     'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tvec__stop_words': ['english'],      \n",
    "    \n",
    "     'ada__estimator': [None], #DecisionTreeClassifier default\n",
    "     'ada__learning_rate': [0.1, 1, 10],\n",
    "     'ada__n_estimators': [10,20,30],\n",
    "}\n",
    "\n",
    "pipe5 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "rs5 = RandomizedSearchCV(estimator=pipe5, param_distributions=params5, cv = 5, n_iter = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3ba14-45c9-4f42-85f8-29542a6685be",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c689a-b452-401b-985c-dff2129d7965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rs5.fit(X_train, y_train)\n",
    "# pickle.dump(rs5, open('./pickled_models/rs5_AdaBoosted_Trees.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d789cce-c98d-4341-a160-c5d2b1b6e57e",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc442e8-53a5-483b-9076-2a9d506a4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_capture = model_performance_capture.append(model_evaluation(rs5, 'Model_5_AdaBoostClassifier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad56b0-a2fb-4787-bb61-0ed9560b85aa",
   "metadata": {},
   "source": [
    "## Single Estimator Models for Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9603bd-d086-4dfb-91e9-47c23a7fe4a4",
   "metadata": {},
   "source": [
    "### 06 Kernelized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a7e3f-5335-4b3f-bd8e-227275bb72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiVectorizer(TransformerMixin):\n",
    "#     def __init__(self, vectorizer='CountVectorizer', **kwargs):  # CountVectorizer as Default\n",
    "#         self.label = vectorizer\n",
    "#         if vectorizer == 'TFIDF':\n",
    "#             self.vectorizer = TfidfVectorizer(**kwargs)\n",
    "#         elif vectorizer == 'CountVectorizer':\n",
    "#             self.vectorizer = CountVectorizer(**kwargs)\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self.vectorizer.fit(X, y)\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         return self.vectorizer.transform(X)\n",
    "    \n",
    "#     def get_params(self, **kwargs):\n",
    "#         return {**self.vectorizer.get_params(**kwargs), 'vectorizer':self.label}\n",
    "    \n",
    "#     def set_params(self, **params):\n",
    "#         return self.vectorizer.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2444a-e944-4c57-8549-72feb4195b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec6 = {\n",
    "     'tvec__preprocessor': [None,lemmatize_post],\n",
    "     'tvec__max_df': np.linspace(0.75, 0.95,6),              \n",
    "     'tvec__max_features': [4000, 5000, 6000], \n",
    "     'tvec__min_df': [1],\n",
    "     'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tvec__stop_words': ['english'],\n",
    "}\n",
    "\n",
    "ksvm_params6 = {\n",
    "    'ksvm__C': np.linspace(0.05, 2, 7),\n",
    "    'ksvm__degree': [2, 3],\n",
    "    'ksvm__kernel': ['poly', 'rbf']\n",
    "}\n",
    "\n",
    "params6 = {\n",
    "    **tvec6, **ksvm_params6\n",
    "}\n",
    "\n",
    "pipe6 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('ksvm', SVC())\n",
    "])\n",
    "pipe6.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbfdd4-8eec-43ff-a89f-11b203cdc66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs6 = RandomizedSearchCV(estimator=pipe6,\n",
    "                        param_distributions=params6,\n",
    "                        cv = 5,\n",
    "                        n_iter = 1\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da605297-d2c5-4fc2-9697-b1ae162954d7",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93745933-8272-4266-a258-75eec741f370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time\n",
    "rs6.fit(X_train, y_train)\n",
    "# pickle.dump(rs6, open('./pickled_models/rs6_SVM_Multi_Vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c14d04-3cd4-461d-b8ec-d8e27eea6db9",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177ce49-a34b-47a4-9378-c1c18680b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_capture = model_performance_capture.append(model_evaluation(rs6, 'Model_6_SVM_TFIDF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69448de-d2ca-495c-b618-e8ba462db899",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d826dd5-586f-4a3d-8975-3d9971c8fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cite: mors: https://stackoverflow.com/questions/42920148/using-sklearn-voting-ensemble-with-partial-fit\n",
    "# VotingClassifier Ensembling without model refit.\n",
    "classifier_list = [rs1, rs2, rs3, rs4, rs5, rs6]\n",
    "\n",
    "classifier_estimators = VotingClassifier(estimators = [('Model_1_RSCV_Multi_Tfidf' ,rs1),\n",
    "                                                       ('Model_2_RsCV_Multi_CVEC', rs2),\n",
    "                                                       ('Model_3_Bagged_Trees', rs3),\n",
    "                                                      ('Model_4_Random_Forrest', rs4),\n",
    "                                                      ('Model_5_AdaBoostClassifier', rs5),\n",
    "                                                      ('Model_6_SVM_TFIDF', rs6)], voting='soft')\n",
    "\n",
    "classifier_estimators.estimators_ = classifier_list\n",
    "classifier_estimators.le_ = LabelEncoder().fit(y)\n",
    "classifier_estimators.classes_ = classifier_estimators.le_.classes_\n",
    "\n",
    "# Now it will work without calling fit\n",
    "classifier_estimators.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627af59b-294a-4276-805f-d2d7e0a8f63a",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec99838-c900-4655-92b0-73c36803a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_capture = model_performance_capture.append(model_evaluation(classifier_estimators, 'Model_7_VotingClassifier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787bc49-9d5a-4344-b2df-f4fd6ac67dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df9cf7-3683-4716-a996-f22de63edeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
